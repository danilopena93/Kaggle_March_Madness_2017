{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Daynum</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Wloc</th>\n",
       "      <th>Numot</th>\n",
       "      <th>Wfgm</th>\n",
       "      <th>Wfga</th>\n",
       "      <th>...</th>\n",
       "      <th>Lfga3</th>\n",
       "      <th>Lftm</th>\n",
       "      <th>Lfta</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot  Wfgm  Wfga ...   \\\n",
       "0    2003      10   1104      68   1328      62    N      0    27    58 ...    \n",
       "1    2003      10   1272      70   1393      63    N      0    26    62 ...    \n",
       "2    2003      11   1266      73   1437      61    N      0    24    58 ...    \n",
       "3    2003      11   1296      56   1457      50    N      0    18    38 ...    \n",
       "4    2003      11   1400      77   1208      71    N      0    30    61 ...    \n",
       "\n",
       "   Lfga3  Lftm  Lfta  Lor  Ldr  Last  Lto  Lstl  Lblk  Lpf  \n",
       "0     10    16    22   10   22     8   18     9     2   20  \n",
       "1     24     9    20   20   25     7   12     8     6   16  \n",
       "2     26    14    23   31   22     9   12     2     5   23  \n",
       "3     22     8    15   17   20     9   19     4     3   23  \n",
       "4     16    17    27   21   15    12   10     7     1   14  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "csv = ['/RegularSeasonCompactResults.csv',\n",
    "'/RegularSeasonDetailedResults.csv',\n",
    "'/Seasons.csv',\n",
    "'/Teams.csv',\n",
    "'/TourneyCompactResults.csv',\n",
    "'/TourneyDetailedResults.csv',\n",
    "'/TourneySeeds.csv',\n",
    "'/TourneySlots.csv',\n",
    "'/SampleSubmission.csv']\n",
    "direct = 'C:/Users/danil/Downloads/Data/March_Madness'\n",
    "sea_det = pd.read_csv(direct+csv[1])\n",
    "sea_det.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to demonstrate logistic regression and KNN algorithms to minimize log loss. We will submit this algoritm in the 2017 March Madness competition on Kaggle. It looks like there is a lot of data to play with in the 'Regular Season Detailed Results'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Daynum</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Wloc</th>\n",
       "      <th>Numot</th>\n",
       "      <th>Wfgm</th>\n",
       "      <th>Wfga</th>\n",
       "      <th>...</th>\n",
       "      <th>Lfga3</th>\n",
       "      <th>Lftm</th>\n",
       "      <th>Lfta</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28825</th>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1181</td>\n",
       "      <td>80</td>\n",
       "      <td>1342</td>\n",
       "      <td>49</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28826</th>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1204</td>\n",
       "      <td>65</td>\n",
       "      <td>1222</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>1181</td>\n",
       "      <td>97</td>\n",
       "      <td>1204</td>\n",
       "      <td>54</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>1222</td>\n",
       "      <td>76</td>\n",
       "      <td>1342</td>\n",
       "      <td>57</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>1318</td>\n",
       "      <td>73</td>\n",
       "      <td>1237</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot  Wfgm  Wfga  \\\n",
       "28825    2009       7   1181      80   1342      49    H      0    30    63   \n",
       "28826    2009       7   1204      65   1222      63    N      0    24    62   \n",
       "28827    2009       8   1181      97   1204      54    H      0    32    66   \n",
       "28828    2009       8   1222      76   1342      57    N      0    30    56   \n",
       "28829    2009       8   1318      73   1237      60    N      0    21    50   \n",
       "\n",
       "      ...   Lfga3  Lftm  Lfta  Lor  Ldr  Last  Lto  Lstl  Lblk  Lpf  \n",
       "28825 ...      17    14    19   10   19     4   28     5     5   25  \n",
       "28826 ...      20    16    27   15   22     9   14     6     2   21  \n",
       "28827 ...      19    13    21   16   20     6   17     5     6   28  \n",
       "28828 ...      21    19    24    8   20     8   19     5     3   18  \n",
       "28829 ...      17    18    26   13   19     7    9     3     4   22  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sea_det = sea_det[sea_det['Season']>=2009]\n",
    "sea_det.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I experimentally found that using seasons 2009 and onward were best for fitting the model. This may be because we do not want to go too far to explain wins that are more than a decade apart. There were a lot of changes how the game is played, teams, coaches, etc. The data would not be able to show this variation in the team itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function will return win percentage, field goal pct, 3pt pct, and Free throw pct of past x games\n",
    "def get_past(num, season, team):\n",
    "    df = sea_det[(sea_det['Wteam'] == team) | (sea_det['Lteam'] == team)]\n",
    "    df = df[df['Season'] == season]\n",
    "    df = df.sort_values(by = ['Daynum'])\n",
    "    df_1 = df.iloc[-num:]\n",
    "    wins = np.sum([df.iloc[-num:]['Wteam'] == team])\n",
    "    win_pct = wins/len(df.iloc[-num:]['Wteam'] == team)\n",
    "    \n",
    "    Wfgp_n = np.mean((df_1['Wfgm']/df_1['Wfga']))\n",
    "    Wfg3p_n = np.mean((df_1['Wfgm3']/df_1['Wfga3']))\n",
    "    Wftp_n = np.mean((df_1['Wftm']/df_1['Wfta']))\n",
    "    \n",
    "    return win_pct, Wfgp_n, Wfg3p_n, Wftp_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function will populate a table that will record 'Elo Scores'. This score is a common way to judge how good a team is in \n",
    "#the NCAA. This was one of the best predictors for the target variable. \n",
    "import math\n",
    "base_elo = 1600\n",
    "team_elos = pd.DataFrame()\n",
    "for i in range(2009, 2017):\n",
    "    for j in sea_det['Wteam'].unique():\n",
    "        x = []\n",
    "        x.append(i)\n",
    "        x.append(j)\n",
    "        x.append(1600)\n",
    "        team_elos = team_elos.append([x], ignore_index= True)\n",
    "team_elos.columns = ['Season','Team','Elo']\n",
    "\n",
    "def calc_elo(win_team, lose_team, season):\n",
    "    \n",
    "    season_df = team_elos[team_elos['Season'] == season]\n",
    "    winner_rank = int(season_df[season_df['Team'] == win_team]['Elo'])\n",
    "    loser_rank = int(season_df[season_df['Team'] == lose_team]['Elo'])\n",
    "\n",
    "    rank_diff = winner_rank - loser_rank\n",
    "    exp = (rank_diff * -1) / 400\n",
    "    odds = 1 / (1 + math.pow(10, exp))\n",
    "    if winner_rank < 2100:\n",
    "        k = 32\n",
    "    elif winner_rank >= 2100 and winner_rank < 2400:\n",
    "        k = 24\n",
    "    else:\n",
    "        k = 16\n",
    "    new_winner_rank = round(winner_rank + (k * (1 - odds)))\n",
    "    new_rank_diff = new_winner_rank - winner_rank\n",
    "    new_loser_rank = loser_rank - new_rank_diff\n",
    "    \n",
    "    win_index = team_elos.loc[(team_elos['Season'] == season) & (team_elos['Team'] == win_team)].index\n",
    "    lose_index = team_elos.loc[(team_elos['Season'] == season) & (team_elos['Team'] == lose_team)].index\n",
    "    \n",
    "    team_elos.set_value(win_index,'Elo',new_winner_rank)\n",
    "    team_elos.set_value(lose_index,'Elo',new_loser_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-bdffd743d0a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lteam'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mseason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Season'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcalc_elo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-165459fdffea>\u001b[0m in \u001b[0;36mcalc_elo\u001b[0;34m(win_team, lose_team, season)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mseason_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mteam_elos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mteam_elos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Season'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mseason\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mwinner_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mwin_team\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Elo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mloser_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseason_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlose_team\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Elo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         raise TypeError(\"cannot convert the series to \"\n\u001b[0;32m---> 78\u001b[0;31m                         \"{0}\".format(str(converter)))\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert the series to <class 'int'>"
     ]
    }
   ],
   "source": [
    "#Computes the Elo Score\n",
    "for ii, row in sea_det.iterrows():\n",
    "    win = row['Wteam']\n",
    "    lose = row['Lteam']\n",
    "    season = row['Season']\n",
    "    calc_elo(win,lose,season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Tfgp5</th>\n",
       "      <th>Tfgp10</th>\n",
       "      <th>Tfgp15</th>\n",
       "      <th>Wfgp</th>\n",
       "      <th>Wfg3p</th>\n",
       "      <th>Wftp</th>\n",
       "      <th>Wor</th>\n",
       "      <th>Wdr</th>\n",
       "      <th>...</th>\n",
       "      <th>Lfgm3</th>\n",
       "      <th>Lftm</th>\n",
       "      <th>NLoss</th>\n",
       "      <th>Lspr</th>\n",
       "      <th>Wpct</th>\n",
       "      <th>Lpct</th>\n",
       "      <th>L5g</th>\n",
       "      <th>Wfgp_n</th>\n",
       "      <th>Wfg3p_n</th>\n",
       "      <th>Wftp_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1181</td>\n",
       "      <td>0.499590</td>\n",
       "      <td>0.494136</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.479362</td>\n",
       "      <td>0.398185</td>\n",
       "      <td>0.733809</td>\n",
       "      <td>12.024390</td>\n",
       "      <td>25.276423</td>\n",
       "      <td>...</td>\n",
       "      <td>7.160714</td>\n",
       "      <td>13.821429</td>\n",
       "      <td>56</td>\n",
       "      <td>-8.500000</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.460677</td>\n",
       "      <td>0.382896</td>\n",
       "      <td>0.717298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1204</td>\n",
       "      <td>0.482320</td>\n",
       "      <td>0.475725</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>0.459050</td>\n",
       "      <td>0.385639</td>\n",
       "      <td>0.687424</td>\n",
       "      <td>10.160000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.121212</td>\n",
       "      <td>12.836364</td>\n",
       "      <td>165</td>\n",
       "      <td>-12.975758</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.486208</td>\n",
       "      <td>0.411904</td>\n",
       "      <td>0.717406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1222</td>\n",
       "      <td>0.418215</td>\n",
       "      <td>0.431397</td>\n",
       "      <td>0.449586</td>\n",
       "      <td>0.475491</td>\n",
       "      <td>0.395419</td>\n",
       "      <td>0.733747</td>\n",
       "      <td>11.896104</td>\n",
       "      <td>25.980519</td>\n",
       "      <td>...</td>\n",
       "      <td>6.008000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>125</td>\n",
       "      <td>-10.208000</td>\n",
       "      <td>0.551971</td>\n",
       "      <td>0.448029</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.458193</td>\n",
       "      <td>0.313717</td>\n",
       "      <td>0.782055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1318</td>\n",
       "      <td>0.475120</td>\n",
       "      <td>0.490341</td>\n",
       "      <td>0.487870</td>\n",
       "      <td>0.480038</td>\n",
       "      <td>0.417612</td>\n",
       "      <td>0.742429</td>\n",
       "      <td>8.993289</td>\n",
       "      <td>23.758389</td>\n",
       "      <td>...</td>\n",
       "      <td>5.632353</td>\n",
       "      <td>12.889706</td>\n",
       "      <td>136</td>\n",
       "      <td>-8.816176</td>\n",
       "      <td>0.522807</td>\n",
       "      <td>0.477193</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.478310</td>\n",
       "      <td>0.382523</td>\n",
       "      <td>0.754291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.473207</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.433992</td>\n",
       "      <td>0.456243</td>\n",
       "      <td>0.364282</td>\n",
       "      <td>0.734857</td>\n",
       "      <td>9.194444</td>\n",
       "      <td>24.268519</td>\n",
       "      <td>...</td>\n",
       "      <td>5.796407</td>\n",
       "      <td>11.425150</td>\n",
       "      <td>167</td>\n",
       "      <td>-11.491018</td>\n",
       "      <td>0.392727</td>\n",
       "      <td>0.607273</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.448947</td>\n",
       "      <td>0.333711</td>\n",
       "      <td>0.742080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Team     Tfgp5    Tfgp10    Tfgp15      Wfgp     Wfg3p      Wftp  \\\n",
       "0    2009  1181  0.499590  0.494136  0.500993  0.479362  0.398185  0.733809   \n",
       "1    2009  1204  0.482320  0.475725  0.473250  0.459050  0.385639  0.687424   \n",
       "2    2009  1222  0.418215  0.431397  0.449586  0.475491  0.395419  0.733747   \n",
       "3    2009  1318  0.475120  0.490341  0.487870  0.480038  0.417612  0.742429   \n",
       "4    2009  1275  0.473207  0.453115  0.433992  0.456243  0.364282  0.734857   \n",
       "\n",
       "         Wor        Wdr    ...        Lfgm3       Lftm  NLoss       Lspr  \\\n",
       "0  12.024390  25.276423    ...     7.160714  13.821429     56  -8.500000   \n",
       "1  10.160000  24.750000    ...     6.121212  12.836364    165 -12.975758   \n",
       "2  11.896104  25.980519    ...     6.008000  12.200000    125 -10.208000   \n",
       "3   8.993289  23.758389    ...     5.632353  12.889706    136  -8.816176   \n",
       "4   9.194444  24.268519    ...     5.796407  11.425150    167 -11.491018   \n",
       "\n",
       "       Wpct      Lpct       L5g    Wfgp_n   Wfg3p_n    Wftp_n  \n",
       "0  0.814570  0.185430  0.666667  0.460677  0.382896  0.717298  \n",
       "1  0.377358  0.622642  0.200000  0.486208  0.411904  0.717406  \n",
       "2  0.551971  0.448029  0.600000  0.458193  0.313717  0.782055  \n",
       "3  0.522807  0.477193  0.533333  0.478310  0.382523  0.754291  \n",
       "4  0.392727  0.607273  0.533333  0.448947  0.333711  0.742080  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This dataframe will compute a lot of the 'x' variables that will be critical for the model. We compute 39 predictors. \n",
    "wins = pd.DataFrame()\n",
    "wins_col = ['Season','Wteam', 'Wfgm', 'Wfga', 'Wfgm3', 'Wfga3', 'Wftm',\n",
    "       'Wfta', 'Wor', 'Wdr', 'Wast', 'Wto', 'Wstl', 'Wblk', 'Wpf','Wscore','Lscore']\n",
    "for i in wins_col:\n",
    "    wins[i] = sea_det[i]\n",
    "    \n",
    "loss = pd.DataFrame()\n",
    "loss_col = ['Lteam', 'Lfgm','Lfga', 'Lfgm3', 'Lfga3', 'Lftm', 'Lfta', \n",
    "            'Lor', 'Ldr', 'Last', 'Lto','Lstl', 'Lblk', 'Lpf','Wscore','Lscore']\n",
    "for i in loss_col:\n",
    "    loss[i] = sea_det[i]\n",
    "\n",
    "f_df = pd.DataFrame()\n",
    "#print(type(wins['Wteam'].unique()))\n",
    "for season in sea_det['Season'].unique():\n",
    "    for k in wins['Wteam'].unique():\n",
    "        ar = []\n",
    "        ar.append(season)\n",
    "        ar.append(k)\n",
    "        #last games\n",
    "        five_df = sea_det[sea_det['Wteam']==k].iloc[-5:]\n",
    "        ten_df = sea_det[sea_det['Wteam']==k].iloc[-10:]\n",
    "        fifteen_df = sea_det[sea_det['Wteam']==k].iloc[-15:]\n",
    "        Tfgp5 = np.mean((five_df['Wfgm']/five_df['Wfga']))\n",
    "        Tfgp10 = np.mean((ten_df['Wfgm']/ten_df['Wfga']))\n",
    "        Tfgp15 = np.mean((fifteen_df['Wfgm']/fifteen_df['Wfga']))\n",
    "        ar.append(Tfgp5)\n",
    "        ar.append(Tfgp10)\n",
    "        ar.append(Tfgp15)\n",
    "\n",
    "        #wins\n",
    "        wins_df = wins[wins['Wteam'] == k]\n",
    "        #season = wins['Season']\n",
    "\n",
    "        Wfgp = np.mean((wins_df['Wfgm']/wins_df['Wfga']))\n",
    "        Wfg3p = np.mean((wins_df['Wfgm3']/wins_df['Wfga3']))\n",
    "        Wftp = np.mean((wins_df['Wftm']/wins_df['Wfta']))\n",
    "        #ar.append(season)\n",
    "        ar.append(Wfgp)\n",
    "        ar.append(Wfg3p)\n",
    "        ar.append(Wftp)\n",
    "\n",
    "        other = ['Wor','Wdr','Wast','Wto','Wstl','Wblk','Wpf','Wfgm','Wfgm3','Wftm']\n",
    "        for i in other:\n",
    "            metric = np.mean(wins_df[i])\n",
    "            ar.append(metric)\n",
    "        NWins = wins_df.shape[0]\n",
    "        ar.append(NWins)\n",
    "\n",
    "        Wspr = np.mean((wins_df['Wscore'] - wins_df['Lscore']))\n",
    "        ar.append(Wspr)\n",
    "\n",
    "        #losses\n",
    "        loss_df = loss[loss['Lteam'] == k]\n",
    "\n",
    "        Lfgp = np.mean((loss_df['Lfgm']/loss_df['Lfga']))\n",
    "        Lfg3p = np.mean((loss_df['Lfgm3']/loss_df['Lfga3']))\n",
    "        Lftp = np.mean((loss_df['Lftm']/loss_df['Lfta']))\n",
    "\n",
    "        ar.append(Lfgp)\n",
    "        ar.append(Lfg3p)\n",
    "        ar.append(Lftp)\n",
    "        other = ['Lor','Ldr','Last','Lto','Lstl','Lblk','Lpf','Lfgm','Lfgm3','Lftm']\n",
    "        for i in other:\n",
    "            metric = np.mean(loss_df[i])\n",
    "            ar.append(metric)\n",
    "        NLoss = loss_df.shape[0]\n",
    "        ar.append(NLoss)\n",
    "\n",
    "        Lspr = np.mean((loss_df['Lscore'] - loss_df['Wscore']))\n",
    "        ar.append(Lspr)\n",
    "\n",
    "        Wpct = NWins/(NWins+NLoss)\n",
    "        ar.append(Wpct)\n",
    "\n",
    "        Lpct = NLoss/(NWins+NLoss)\n",
    "        ar.append(Lpct)\n",
    "        array = get_past(15,season,k)\n",
    "        for i in array:\n",
    "            ar.append(i)\n",
    "\n",
    "        f_df = f_df.append([ar], ignore_index= True)\n",
    "f_df.columns = ['Season','Team','Tfgp5','Tfgp10','Tfgp15','Wfgp','Wfg3p','Wftp','Wor','Wdr','Wast',\n",
    "                               'Wto','Wstl','Wblk','Wpf','Wfgm','Wfgm3','Wftm',\n",
    "                                'NWins','Wspr','Lfgp',\n",
    "                               'Lfg3p','Lftp','Lor','Ldr','Last',\n",
    "                               'Lto','Lstl','Lblk','Lpf','Lfgm','Lfgm3','Lftm','NLoss','Lspr',\n",
    "                            'Wpct','Lpct','L5g','Wfgp_n','Wfg3p_n','Wftp_n']\n",
    "f_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Tfgp5</th>\n",
       "      <th>Tfgp10</th>\n",
       "      <th>Tfgp15</th>\n",
       "      <th>Wfgp</th>\n",
       "      <th>Wfg3p</th>\n",
       "      <th>Wftp</th>\n",
       "      <th>Wor</th>\n",
       "      <th>Wdr</th>\n",
       "      <th>...</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "      <th>Lfgm</th>\n",
       "      <th>Lfgm3</th>\n",
       "      <th>NLoss</th>\n",
       "      <th>Lspr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1181</td>\n",
       "      <td>0.499590</td>\n",
       "      <td>0.494136</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>0.479362</td>\n",
       "      <td>0.398185</td>\n",
       "      <td>0.733809</td>\n",
       "      <td>12.024390</td>\n",
       "      <td>25.276423</td>\n",
       "      <td>...</td>\n",
       "      <td>12.339286</td>\n",
       "      <td>11.339286</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>6.053571</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>7.160714</td>\n",
       "      <td>56</td>\n",
       "      <td>-8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1204</td>\n",
       "      <td>0.482320</td>\n",
       "      <td>0.475725</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>0.459050</td>\n",
       "      <td>0.385639</td>\n",
       "      <td>0.687424</td>\n",
       "      <td>10.160000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.036364</td>\n",
       "      <td>10.254545</td>\n",
       "      <td>14.236364</td>\n",
       "      <td>6.969697</td>\n",
       "      <td>2.303030</td>\n",
       "      <td>20.581818</td>\n",
       "      <td>22.715152</td>\n",
       "      <td>6.121212</td>\n",
       "      <td>165</td>\n",
       "      <td>-12.975758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1222</td>\n",
       "      <td>0.418215</td>\n",
       "      <td>0.431397</td>\n",
       "      <td>0.449586</td>\n",
       "      <td>0.475491</td>\n",
       "      <td>0.395419</td>\n",
       "      <td>0.733747</td>\n",
       "      <td>11.896104</td>\n",
       "      <td>25.980519</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920000</td>\n",
       "      <td>11.272000</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>5.816000</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>19.368000</td>\n",
       "      <td>23.592000</td>\n",
       "      <td>6.008000</td>\n",
       "      <td>125</td>\n",
       "      <td>-10.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1318</td>\n",
       "      <td>0.475120</td>\n",
       "      <td>0.490341</td>\n",
       "      <td>0.487870</td>\n",
       "      <td>0.480038</td>\n",
       "      <td>0.417612</td>\n",
       "      <td>0.742429</td>\n",
       "      <td>8.993289</td>\n",
       "      <td>23.758389</td>\n",
       "      <td>...</td>\n",
       "      <td>10.367647</td>\n",
       "      <td>11.742647</td>\n",
       "      <td>13.176471</td>\n",
       "      <td>6.477941</td>\n",
       "      <td>3.036765</td>\n",
       "      <td>18.161765</td>\n",
       "      <td>22.345588</td>\n",
       "      <td>5.632353</td>\n",
       "      <td>136</td>\n",
       "      <td>-8.816176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.473207</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.433992</td>\n",
       "      <td>0.456243</td>\n",
       "      <td>0.364282</td>\n",
       "      <td>0.734857</td>\n",
       "      <td>9.194444</td>\n",
       "      <td>24.268519</td>\n",
       "      <td>...</td>\n",
       "      <td>8.712575</td>\n",
       "      <td>11.029940</td>\n",
       "      <td>13.796407</td>\n",
       "      <td>6.059880</td>\n",
       "      <td>2.508982</td>\n",
       "      <td>18.982036</td>\n",
       "      <td>21.724551</td>\n",
       "      <td>5.796407</td>\n",
       "      <td>167</td>\n",
       "      <td>-11.491018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Team     Tfgp5    Tfgp10    Tfgp15      Wfgp     Wfg3p      Wftp  \\\n",
       "0    2009  1181  0.499590  0.494136  0.500993  0.479362  0.398185  0.733809   \n",
       "1    2009  1204  0.482320  0.475725  0.473250  0.459050  0.385639  0.687424   \n",
       "2    2009  1222  0.418215  0.431397  0.449586  0.475491  0.395419  0.733747   \n",
       "3    2009  1318  0.475120  0.490341  0.487870  0.480038  0.417612  0.742429   \n",
       "4    2009  1275  0.473207  0.453115  0.433992  0.456243  0.364282  0.734857   \n",
       "\n",
       "         Wor        Wdr    ...            Lor       Last        Lto      Lstl  \\\n",
       "0  12.024390  25.276423    ...      12.339286  11.339286  11.428571  6.053571   \n",
       "1  10.160000  24.750000    ...      11.036364  10.254545  14.236364  6.969697   \n",
       "2  11.896104  25.980519    ...      11.920000  11.272000  12.760000  5.816000   \n",
       "3   8.993289  23.758389    ...      10.367647  11.742647  13.176471  6.477941   \n",
       "4   9.194444  24.268519    ...       8.712575  11.029940  13.796407  6.059880   \n",
       "\n",
       "       Lblk        Lpf       Lfgm     Lfgm3  NLoss       Lspr  \n",
       "0  3.178571  20.285714  24.875000  7.160714     56  -8.500000  \n",
       "1  2.303030  20.581818  22.715152  6.121212    165 -12.975758  \n",
       "2  3.392000  19.368000  23.592000  6.008000    125 -10.208000  \n",
       "3  3.036765  18.161765  22.345588  5.632353    136  -8.816176  \n",
       "4  2.508982  18.982036  21.724551  5.796407    167 -11.491018  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This bit of code will get the top 32 predictors. \n",
    "for item in range(32, len(x)):\n",
    "    col = x[item][1]\n",
    "    f_df.drop(col,axis=1,inplace=True)\n",
    "\n",
    "f_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Season</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Lteam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2045</td>\n",
       "      <td>2016</td>\n",
       "      <td>1314</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2046</td>\n",
       "      <td>2016</td>\n",
       "      <td>1393</td>\n",
       "      <td>1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2047</td>\n",
       "      <td>2016</td>\n",
       "      <td>1314</td>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2048</td>\n",
       "      <td>2016</td>\n",
       "      <td>1437</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2049</td>\n",
       "      <td>2016</td>\n",
       "      <td>1437</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Season  Wteam  Lteam\n",
       "397   2045    2016   1314   1323\n",
       "398   2046    2016   1393   1438\n",
       "399   2047    2016   1314   1393\n",
       "400   2048    2016   1437   1328\n",
       "401   2049    2016   1437   1314"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code will get all of the tournament results from seasons 2011-2016. The idea is to not use all of the data to reduce \n",
    "#overfitting. I also thought that data that is closer to 2017 will better capture the variations in the way the game is played.\n",
    "#Ex - the way players shoot, pass, defend will be more alike the last year than the last 5 years.\n",
    "df_tour = pd.read_csv(direct + csv[4])\n",
    "df_tour.drop(labels=['Daynum', 'Wscore', 'Lscore', 'Wloc', 'Numot'], \n",
    "             inplace=True, axis=1)\n",
    "\n",
    "df_tour = df_tour[(df_tour['Season'] == 2011)|(df_tour['Season'] == 2012)\n",
    "                  |(df_tour['Season'] == 2013)|(df_tour['Season'] == 2014)|\n",
    "                  (df_tour['Season'] == 2015)|(df_tour['Season'] == 2016)]\n",
    "df_tour = df_tour.reset_index()\n",
    "df_tour.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code computes the difference between the winner team tournament wins and the losing team tournament wins. The idea here was\n",
    "#to give a better team a higher chance of winning a matchup if they have won tournament games in the past. \n",
    "def get_tourney_diff(wteam,lteam,season):\n",
    "        x = df_tour[(df_tour['Season'] == season-1)]\n",
    "        Wteam = wteam\n",
    "        Lteam = lteam\n",
    "        w_df = x[x['Wteam']==Wteam]\n",
    "        l_df = x[x['Wteam']==Lteam]\n",
    "        return (int(len(w_df)) - int(len(l_df)))\n",
    "get_tourney_diff(1155,1412,2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculates the Elo Score difference between 2 teams. \n",
    "def get_elo_diff(team1,team2,season):\n",
    "    season_df = team_elos[team_elos['Season'] == season]\n",
    "    team1_rank = season_df[season_df['Team'] == team1].values[0][2]\n",
    "    team2_rank = season_df[season_df['Team'] == team2].values[0][2]\n",
    "    return (team1_rank - team2_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The code below was not used in the algorithm. The idea here was to compute differences within the Detailed portion of the \n",
    "#Tournament data. It would be interesting to explore how teams play differently in the tournament setting \n",
    "df_seeds = pd.read_csv(direct + csv[6])\n",
    "def seed_to_int(seed):\n",
    "    \"\"\"Get just the digits from the seeding. Return as int\"\"\"\n",
    "    s_int = int(seed[1:3])\n",
    "    return s_int\n",
    "df_seeds['n_seed'] = df_seeds.Seed.apply(seed_to_int)\n",
    "def get_seed(team1,team2,season):\n",
    "    x = df_seeds[(df_seeds['Season'] == season)]\n",
    "    teams = [team1,team2]\n",
    "    team1_seed = 0\n",
    "    team2_seed = 0\n",
    "    if team1 in x['Team'].unique():\n",
    "        team1_seed = x.loc[x['Team'] == team1]['n_seed']\n",
    "    else:\n",
    "        team1_seed = 0\n",
    "    if team2 in x['Team'].unique():\n",
    "        team2_seed = x.loc[x['Team'] == team2]['n_seed']\n",
    "    else:\n",
    "        team2_seed = 0\n",
    "    return (team1_seed - team2_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Tfgp5</th>\n",
       "      <th>Tfgp10</th>\n",
       "      <th>Tfgp15</th>\n",
       "      <th>Wfgp</th>\n",
       "      <th>Wfg3p</th>\n",
       "      <th>Wftp</th>\n",
       "      <th>Wor</th>\n",
       "      <th>Wdr</th>\n",
       "      <th>...</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "      <th>Lfgm</th>\n",
       "      <th>Lfgm3</th>\n",
       "      <th>NLoss</th>\n",
       "      <th>Lspr</th>\n",
       "      <th>tourney_diff</th>\n",
       "      <th>elo_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.743143</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.743143</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.743143</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.743143</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.743143</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season   Team     Tfgp5    Tfgp10    Tfgp15      Wfgp     Wfg3p      Wftp  \\\n",
       "0     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "1     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "2     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "3     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "4     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "\n",
       "        Wor       Wdr    ...          Lto    Lstl      Lblk       Lpf  \\\n",
       "0 -0.289705 -1.766591    ...    -1.743143  0.5453  0.945609 -1.035901   \n",
       "1 -0.289705 -1.766591    ...    -1.743143  0.5453  0.945609 -1.035901   \n",
       "2 -0.289705 -1.766591    ...    -1.743143  0.5453  0.945609 -1.035901   \n",
       "3 -0.289705 -1.766591    ...    -1.743143  0.5453  0.945609 -1.035901   \n",
       "4 -0.289705 -1.766591    ...    -1.743143  0.5453  0.945609 -1.035901   \n",
       "\n",
       "       Lfgm     Lfgm3  NLoss      Lspr  tourney_diff  elo_diff  \n",
       "0 -0.556703  0.577504    8.0  1.523729             0       -37  \n",
       "1 -0.556703  0.577504    8.0  1.523729             0       -37  \n",
       "2 -0.556703  0.577504    8.0  1.523729             0       -37  \n",
       "3 -0.556703  0.577504    8.0  1.523729             0       -37  \n",
       "4 -0.556703  0.577504    8.0  1.523729             0       -37  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The only way to compare the two teams that are going against each other is to either add or subtract their stats. This table \n",
    "#below computes the differences.\n",
    "def create_diff_table(tour):\n",
    "    df_diff = pd.DataFrame()\n",
    "    ar = []\n",
    "    for i in range(0,len(tour)):\n",
    "        season = tour['Season'][i]\n",
    "        wteam = tour['Wteam'][i]   \n",
    "        lteam = tour['Lteam'][i] \n",
    "        wteam_stat = (f_df.loc[f_df['Team'] == wteam])\n",
    "        lteam_stat = (f_df.loc[f_df['Team'] == lteam])\n",
    "        diff = pd.DataFrame(wteam_stat.values - lteam_stat.values, columns = wteam_stat.columns)\n",
    "        diff['tourney_diff'] = get_tourney_diff(wteam,lteam,season)\n",
    "        diff['elo_diff'] = get_elo_diff(wteam,lteam,season)\n",
    "        df_diff = df_diff.append([diff], ignore_index= True)\n",
    "    return df_diff\n",
    "df_diff = create_diff_table(df_tour)\n",
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3618, 34)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Tfgp5</th>\n",
       "      <th>Tfgp10</th>\n",
       "      <th>Tfgp15</th>\n",
       "      <th>Wfgp</th>\n",
       "      <th>Wfg3p</th>\n",
       "      <th>Wftp</th>\n",
       "      <th>Wor</th>\n",
       "      <th>Wdr</th>\n",
       "      <th>...</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "      <th>Lfgm</th>\n",
       "      <th>Lfgm3</th>\n",
       "      <th>NLoss</th>\n",
       "      <th>Lspr</th>\n",
       "      <th>tourney_diff</th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-257.0</td>\n",
       "      <td>-0.039931</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>-0.038491</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>-0.289705</td>\n",
       "      <td>-1.766591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.945609</td>\n",
       "      <td>-1.035901</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.523729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season   Team     Tfgp5    Tfgp10    Tfgp15      Wfgp     Wfg3p      Wftp  \\\n",
       "0     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "1     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "2     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "3     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "4     0.0 -257.0 -0.039931 -0.024042 -0.038491  0.006912 -0.001811 -0.017308   \n",
       "\n",
       "        Wor       Wdr   ...      Lstl      Lblk       Lpf      Lfgm     Lfgm3  \\\n",
       "0 -0.289705 -1.766591   ...    0.5453  0.945609 -1.035901 -0.556703  0.577504   \n",
       "1 -0.289705 -1.766591   ...    0.5453  0.945609 -1.035901 -0.556703  0.577504   \n",
       "2 -0.289705 -1.766591   ...    0.5453  0.945609 -1.035901 -0.556703  0.577504   \n",
       "3 -0.289705 -1.766591   ...    0.5453  0.945609 -1.035901 -0.556703  0.577504   \n",
       "4 -0.289705 -1.766591   ...    0.5453  0.945609 -1.035901 -0.556703  0.577504   \n",
       "\n",
       "   NLoss      Lspr  tourney_diff  elo_diff  result  \n",
       "0    8.0  1.523729           0.0     -37.0     1.0  \n",
       "1    8.0  1.523729           0.0     -37.0     1.0  \n",
       "2    8.0  1.523729           0.0     -37.0     1.0  \n",
       "3    8.0  1.523729           0.0     -37.0     1.0  \n",
       "4    8.0  1.523729           0.0     -37.0     1.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There were two ways to assign target variables. The first way, which is commented out, is to duplicate df_diff and assign wins \n",
    "#to all of those rows. Then, take the negative of df_diff and assign losses to all of those rows. Combine and then compute. The\n",
    "#second way is to truly randomize the rows. This is the way I chose since it provided better results. \n",
    "import random\n",
    "\n",
    "# df_wins = pd.DataFrame()\n",
    "# df_wins = df_diff\n",
    "# df_wins['result'] = 1\n",
    "\n",
    "# df_losses = pd.DataFrame()\n",
    "# df_losses = -df_diff\n",
    "# df_losses['result'] = 0\n",
    "\n",
    "# Randomly select left and right and 0 or 1 so we can train\n",
    "#for multiple classes.\n",
    "df_pred = df_diff \n",
    "df_pred['result'] = 1\n",
    "for i in range(len(df_pred)):\n",
    "    if random.random() > 0.5:\n",
    "        df_pred['result'][i] = 1\n",
    "    else:\n",
    "        df_pred.loc[i:i] = -df_diff.loc[i:i]\n",
    "        df_pred['result'][i] = 0 \n",
    "\n",
    "# df_pred = pd.concat((df_wins, df_losses))\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pred_all = df_pred\n",
    "df_pred.drop(['Season','Team'],inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728851547038\n",
      "0.2689331122166943\n",
      "9.28872803665\n"
     ]
    }
   ],
   "source": [
    "#For the logistic regression, I did a KFold cross-validation. \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = df_pred.drop('result',axis=1)\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "\n",
    "y_train = df_pred['result']\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state=8)\n",
    "\n",
    "model_LR= LogisticRegression()\n",
    "params = {'C': np.logspace(start=-5, stop=3, num=9)}\n",
    "model_LR = GridSearchCV(model_LR, params, scoring='neg_log_loss', refit=True)\n",
    "model_LR.fit(X_train,y_train)\n",
    "\n",
    "pred_probs = model_LR.predict_proba(X_train)\n",
    "predictions = model_LR.predict(X_train)\n",
    "\n",
    "#accuracy \n",
    "accuracies = cross_val_score(model_LR, X_train, y_train, scoring='accuracy', cv=kf)\n",
    "average_accuracies = np.mean(accuracies)\n",
    "print(average_accuracies)\n",
    "\n",
    "#mean squared error\n",
    "actual = y_train\n",
    "count= ((predictions-actual)**2).sum()\n",
    "mse = count/len(actual)\n",
    "print(mse)\n",
    "\n",
    "#log loss\n",
    "loss = log_loss(y_train, predictions)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAANYCAYAAADHVnwbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d181bb7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(y_train,predictions)\n",
    "\n",
    "auc_roc=metrics.roc_auc_score(y_train,predictions)\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, pred_probs[:,1])\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],linestyle='--')\n",
    "plt.axis('tight')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.20250000000000001, 'NWins'), (0.068900000000000003, 'elo_diff'), (0.054300000000000001, 'Last'), (0.041399999999999999, 'Wpf'), (0.035299999999999998, 'Lspr'), (0.031899999999999998, 'Tfgp5'), (0.0304, 'Wblk'), (0.027099999999999999, 'Wspr'), (0.026599999999999999, 'Tfgp10'), (0.025600000000000001, 'Lftp'), (0.025399999999999999, 'tourney_diff'), (0.025100000000000001, 'Lto'), (0.0229, 'Lor'), (0.022700000000000001, 'Lfg3p'), (0.021999999999999999, 'Lstl'), (0.021000000000000001, 'Lpf'), (0.020400000000000001, 'Wdr'), (0.020199999999999999, 'NLoss'), (0.019, 'Lfgm3'), (0.018700000000000001, 'Wfgp'), (0.018499999999999999, 'Wftp'), (0.018200000000000001, 'Wfgm'), (0.016899999999999998, 'Wstl'), (0.016, 'Wor'), (0.016, 'Tfgp15'), (0.015800000000000002, 'Wto'), (0.014800000000000001, 'Lfgm'), (0.014800000000000001, 'Lblk'), (0.0143, 'Wast'), (0.014, 'Lfgp'), (0.0129, 'Wftm'), (0.012800000000000001, 'Wfg3p'), (0.0126, 'Ldr'), (0.0121, 'Wfgm3'), (0.0121, 'Lftm'), (0.0047999999999999996, 'Wpct'), (0.0041000000000000003, 'Lpct'), (0.0028999999999999998, 'Wftp_n'), (0.002, 'Wfgp_n'), (0.0016999999999999999, 'L5g'), (0.0012999999999999999, 'Wfg3p_n')]\n"
     ]
    }
   ],
   "source": [
    "#Try to reduce the amount of predictors to reduce the degree of overfitting.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "names = df_pred.columns\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))\n",
    "x = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "9.99200722163e-16\n"
     ]
    }
   ],
   "source": [
    "#KNN Regressor works very well!\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=50, p=2, weights = 'distance')\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state=8)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "predictions = knn.predict(X_train)\n",
    "\n",
    "actual = y_train\n",
    "count= ((predictions-actual)**2).sum()\n",
    "mse = count/len(actual)\n",
    "print(mse)\n",
    "\n",
    "loss = log_loss(y_train, predictions)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3177, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>tourney_diff</th>\n",
       "      <th>elo_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.031413</td>\n",
       "      <td>-0.001380</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>-0.892977</td>\n",
       "      <td>0.360322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>-1.985405</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-2.153955</td>\n",
       "      <td>-0.086864</td>\n",
       "      <td>-0.383710</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>3.617938</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.031825</td>\n",
       "      <td>0.014662</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.010548</td>\n",
       "      <td>-1.650878</td>\n",
       "      <td>0.590513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414427</td>\n",
       "      <td>-1.070789</td>\n",
       "      <td>-0.431900</td>\n",
       "      <td>-1.491935</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>-1.011649</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>1.052419</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.027775</td>\n",
       "      <td>-0.044341</td>\n",
       "      <td>-0.028435</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>-0.016527</td>\n",
       "      <td>1.466094</td>\n",
       "      <td>-0.733381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213589</td>\n",
       "      <td>0.350601</td>\n",
       "      <td>0.439940</td>\n",
       "      <td>-0.695946</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>-1.185435</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>1.762387</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-0.031986</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.030068</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>0.427863</td>\n",
       "      <td>1.435282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751797</td>\n",
       "      <td>-0.451307</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>-0.722549</td>\n",
       "      <td>1.672059</td>\n",
       "      <td>-0.292484</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>1.065196</td>\n",
       "      <td>0</td>\n",
       "      <td>-93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>0.074528</td>\n",
       "      <td>0.036781</td>\n",
       "      <td>0.031761</td>\n",
       "      <td>0.027328</td>\n",
       "      <td>0.040545</td>\n",
       "      <td>0.050168</td>\n",
       "      <td>-2.350135</td>\n",
       "      <td>1.088773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698658</td>\n",
       "      <td>-0.567104</td>\n",
       "      <td>-0.752185</td>\n",
       "      <td>0.302434</td>\n",
       "      <td>2.119382</td>\n",
       "      <td>-0.291823</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1.255150</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1         2         3         4         5         6         7  \\\n",
       "0  0.0  -4.0  0.031413 -0.001380 -0.001637  0.009906  0.012943  0.005511   \n",
       "1  0.0 -12.0  0.031825  0.014662  0.011325 -0.003714  0.007171  0.010548   \n",
       "2  0.0 -25.0  0.027775 -0.044341 -0.028435  0.015373  0.002123 -0.016527   \n",
       "3  0.0 -27.0 -0.031986 -0.006242 -0.007376  0.011718  0.030068  0.013670   \n",
       "4  0.0 -41.0  0.074528  0.036781  0.031761  0.027328  0.040545  0.050168   \n",
       "\n",
       "          8         9    ...           24        25        26        27  \\\n",
       "0 -0.892977  0.360322    ...     0.069444 -1.985405 -0.818267 -2.153955   \n",
       "1 -1.650878  0.590513    ...    -0.414427 -1.070789 -0.431900 -1.491935   \n",
       "2  1.466094 -0.733381    ...     0.213589  0.350601  0.439940 -0.695946   \n",
       "3  0.427863  1.435282    ...     0.751797 -0.451307  0.744444 -0.722549   \n",
       "4 -2.350135  1.088773    ...     0.698658 -0.567104 -0.752185  0.302434   \n",
       "\n",
       "         28        29    30        31  tourney_diff  elo_diff  \n",
       "0 -0.086864 -0.383710 -46.0  3.617938             0       123  \n",
       "1  0.173387 -1.011649 -21.0  1.052419             0        17  \n",
       "2  0.652027 -1.185435 -39.0  1.762387             0       240  \n",
       "3  1.672059 -0.292484 -13.0  1.065196             0       -93  \n",
       "4  2.119382 -0.291823 -17.0  1.255150             0        58  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict and submit!\n",
    "df_sample_sub = pd.read_csv(direct+csv[8])\n",
    "\n",
    "n_test_games = len(df_sample_sub)\n",
    "print(f_df.shape)\n",
    "\n",
    "\n",
    "def get_year_t1_t2(id):\n",
    "    return (int(x) for x in id.split('_'))\n",
    "\n",
    "X_test = np.zeros(shape=(n_test_games, 25))\n",
    "X_test = pd.DataFrame()\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, t1, t2 = get_year_t1_t2(row.Id)\n",
    "    df_calc = f_df[(f_df['Season'] == year)|(f_df['Season'] == year-1)]\n",
    "    t1_stat = (df_calc.loc[f_df['Team'] == t1]).mean()\n",
    "    t2_stat = (df_calc.loc[f_df['Team'] == t2]).mean()\n",
    "    diff = pd.DataFrame(t1_stat.values - t2_stat.values)\n",
    "    diff = diff.transpose()\n",
    "    diff['tourney_diff'] = get_tourney_diff(t1,t2,season)\n",
    "    diff['elo_diff'] = get_elo_diff(t1,t2,season)\n",
    "    X_test = X_test.append([diff], ignore_index= True)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2278, 32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.drop([0,1],inplace = True, axis =1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017_1112_1116</td>\n",
       "      <td>0.737688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017_1112_1124</td>\n",
       "      <td>0.418380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017_1112_1137</td>\n",
       "      <td>0.941528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017_1112_1139</td>\n",
       "      <td>0.629238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017_1112_1153</td>\n",
       "      <td>0.698455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017_1112_1166</td>\n",
       "      <td>0.560248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017_1112_1173</td>\n",
       "      <td>0.664306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017_1112_1181</td>\n",
       "      <td>0.513324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017_1112_1190</td>\n",
       "      <td>0.670839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017_1112_1195</td>\n",
       "      <td>0.866902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017_1112_1196</td>\n",
       "      <td>0.589932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017_1112_1199</td>\n",
       "      <td>0.394605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017_1112_1211</td>\n",
       "      <td>0.692321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017_1112_1233</td>\n",
       "      <td>0.651777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017_1112_1235</td>\n",
       "      <td>0.519091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017_1112_1240</td>\n",
       "      <td>0.846488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017_1112_1242</td>\n",
       "      <td>0.478593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017_1112_1243</td>\n",
       "      <td>0.671765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017_1112_1245</td>\n",
       "      <td>0.843643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017_1112_1246</td>\n",
       "      <td>0.555274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id      Pred\n",
       "0   2017_1112_1116  0.737688\n",
       "1   2017_1112_1124  0.418380\n",
       "2   2017_1112_1137  0.941528\n",
       "3   2017_1112_1139  0.629238\n",
       "4   2017_1112_1153  0.698455\n",
       "5   2017_1112_1166  0.560248\n",
       "6   2017_1112_1173  0.664306\n",
       "7   2017_1112_1181  0.513324\n",
       "8   2017_1112_1190  0.670839\n",
       "9   2017_1112_1195  0.866902\n",
       "10  2017_1112_1196  0.589932\n",
       "11  2017_1112_1199  0.394605\n",
       "12  2017_1112_1211  0.692321\n",
       "13  2017_1112_1233  0.651777\n",
       "14  2017_1112_1235  0.519091\n",
       "15  2017_1112_1240  0.846488\n",
       "16  2017_1112_1242  0.478593\n",
       "17  2017_1112_1243  0.671765\n",
       "18  2017_1112_1245  0.843643\n",
       "19  2017_1112_1246  0.555274"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=scaler.fit_transform(X_test)\n",
    "preds = knn.predict(X_test)\n",
    "\n",
    "clipped_preds = np.clip(preds, 0.025, 0.975)\n",
    "df_sample_sub.Pred = clipped_preds\n",
    "df_sample_sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub.to_csv('danny_mm_17_4_KNN_Final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
