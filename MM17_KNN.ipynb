{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Daynum</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Wloc</th>\n",
       "      <th>Numot</th>\n",
       "      <th>Wfgm</th>\n",
       "      <th>Wfga</th>\n",
       "      <th>...</th>\n",
       "      <th>Lfga3</th>\n",
       "      <th>Lftm</th>\n",
       "      <th>Lfta</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot  Wfgm  Wfga ...   \\\n",
       "0    2003      10   1104      68   1328      62    N      0    27    58 ...    \n",
       "1    2003      10   1272      70   1393      63    N      0    26    62 ...    \n",
       "2    2003      11   1266      73   1437      61    N      0    24    58 ...    \n",
       "3    2003      11   1296      56   1457      50    N      0    18    38 ...    \n",
       "4    2003      11   1400      77   1208      71    N      0    30    61 ...    \n",
       "\n",
       "   Lfga3  Lftm  Lfta  Lor  Ldr  Last  Lto  Lstl  Lblk  Lpf  \n",
       "0     10    16    22   10   22     8   18     9     2   20  \n",
       "1     24     9    20   20   25     7   12     8     6   16  \n",
       "2     26    14    23   31   22     9   12     2     5   23  \n",
       "3     22     8    15   17   20     9   19     4     3   23  \n",
       "4     16    17    27   21   15    12   10     7     1   14  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "csv = ['/RegularSeasonCompactResults.csv',\n",
    "'/RegularSeasonDetailedResults.csv',\n",
    "'/Seasons.csv',\n",
    "'/Teams.csv',\n",
    "'/TourneyCompactResults.csv',\n",
    "'/TourneyDetailedResults.csv',\n",
    "'/TourneySeeds.csv',\n",
    "'/TourneySlots.csv',\n",
    "'/sample_submission.csv']\n",
    "direct = 'C:/Users/danil/Downloads/Data/March_Madness'\n",
    "sea_det = pd.read_csv(direct+csv[1])\n",
    "sea_det.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Wfgm</th>\n",
       "      <th>Wfga</th>\n",
       "      <th>Wfgm3</th>\n",
       "      <th>Wfga3</th>\n",
       "      <th>Wftm</th>\n",
       "      <th>...</th>\n",
       "      <th>Lfga3</th>\n",
       "      <th>Lftm</th>\n",
       "      <th>Lfta</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1104</td>\n",
       "      <td>68</td>\n",
       "      <td>1328</td>\n",
       "      <td>62</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>1272</td>\n",
       "      <td>70</td>\n",
       "      <td>1393</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>1266</td>\n",
       "      <td>73</td>\n",
       "      <td>1437</td>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>1296</td>\n",
       "      <td>56</td>\n",
       "      <td>1457</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>1400</td>\n",
       "      <td>77</td>\n",
       "      <td>1208</td>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Wteam  Wscore  Lteam  Lscore  Wfgm  Wfga  Wfgm3  Wfga3  Wftm ...   \\\n",
       "0    2003   1104      68   1328      62    27    58      3     14    11 ...    \n",
       "1    2003   1272      70   1393      63    26    62      8     20    10 ...    \n",
       "2    2003   1266      73   1437      61    24    58      8     18    17 ...    \n",
       "3    2003   1296      56   1457      50    18    38      3      9    17 ...    \n",
       "4    2003   1400      77   1208      71    30    61      6     14    11 ...    \n",
       "\n",
       "   Lfga3  Lftm  Lfta  Lor  Ldr  Last  Lto  Lstl  Lblk  Lpf  \n",
       "0     10    16    22   10   22     8   18     9     2   20  \n",
       "1     24     9    20   20   25     7   12     8     6   16  \n",
       "2     26    14    23   31   22     9   12     2     5   23  \n",
       "3     22     8    15   17   20     9   19     4     3   23  \n",
       "4     16    17    27   21   15    12   10     7     1   14  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sea_det.drop(labels = ['Numot','Daynum','Wloc'],inplace=True, axis=1)\n",
    "sea_det.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Wfgp</th>\n",
       "      <th>Wfg3p</th>\n",
       "      <th>Wftp</th>\n",
       "      <th>Wor</th>\n",
       "      <th>Wdr</th>\n",
       "      <th>Wast</th>\n",
       "      <th>Wto</th>\n",
       "      <th>Wstl</th>\n",
       "      <th>Wblk</th>\n",
       "      <th>...</th>\n",
       "      <th>Lftp</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "      <th>NLoss</th>\n",
       "      <th>Lspr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1104</td>\n",
       "      <td>0.466998</td>\n",
       "      <td>0.360334</td>\n",
       "      <td>0.698481</td>\n",
       "      <td>11.956522</td>\n",
       "      <td>25.920949</td>\n",
       "      <td>13.375494</td>\n",
       "      <td>12.992095</td>\n",
       "      <td>7.509881</td>\n",
       "      <td>4.865613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692350</td>\n",
       "      <td>11.284916</td>\n",
       "      <td>21.715084</td>\n",
       "      <td>10.458101</td>\n",
       "      <td>13.318436</td>\n",
       "      <td>5.960894</td>\n",
       "      <td>3.782123</td>\n",
       "      <td>19.363128</td>\n",
       "      <td>179</td>\n",
       "      <td>-9.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1272</td>\n",
       "      <td>0.468580</td>\n",
       "      <td>0.361655</td>\n",
       "      <td>0.672943</td>\n",
       "      <td>13.020000</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>15.934286</td>\n",
       "      <td>13.168571</td>\n",
       "      <td>8.771429</td>\n",
       "      <td>5.931429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666579</td>\n",
       "      <td>13.188679</td>\n",
       "      <td>22.726415</td>\n",
       "      <td>11.952830</td>\n",
       "      <td>14.537736</td>\n",
       "      <td>6.830189</td>\n",
       "      <td>5.018868</td>\n",
       "      <td>22.047170</td>\n",
       "      <td>106</td>\n",
       "      <td>-9.245283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1266</td>\n",
       "      <td>0.477928</td>\n",
       "      <td>0.380749</td>\n",
       "      <td>0.721663</td>\n",
       "      <td>11.972028</td>\n",
       "      <td>24.541958</td>\n",
       "      <td>16.433566</td>\n",
       "      <td>12.860140</td>\n",
       "      <td>8.027972</td>\n",
       "      <td>3.604895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681919</td>\n",
       "      <td>11.807947</td>\n",
       "      <td>21.463576</td>\n",
       "      <td>12.523179</td>\n",
       "      <td>13.728477</td>\n",
       "      <td>5.986755</td>\n",
       "      <td>2.609272</td>\n",
       "      <td>20.278146</td>\n",
       "      <td>151</td>\n",
       "      <td>-9.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1296</td>\n",
       "      <td>0.472999</td>\n",
       "      <td>0.401041</td>\n",
       "      <td>0.686996</td>\n",
       "      <td>11.468531</td>\n",
       "      <td>25.174825</td>\n",
       "      <td>13.804196</td>\n",
       "      <td>14.671329</td>\n",
       "      <td>7.286713</td>\n",
       "      <td>3.902098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665492</td>\n",
       "      <td>12.391635</td>\n",
       "      <td>21.665399</td>\n",
       "      <td>11.019011</td>\n",
       "      <td>15.760456</td>\n",
       "      <td>5.817490</td>\n",
       "      <td>2.874525</td>\n",
       "      <td>20.714829</td>\n",
       "      <td>263</td>\n",
       "      <td>-11.802281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.464493</td>\n",
       "      <td>0.366006</td>\n",
       "      <td>0.690015</td>\n",
       "      <td>13.732484</td>\n",
       "      <td>26.812102</td>\n",
       "      <td>13.671975</td>\n",
       "      <td>12.299363</td>\n",
       "      <td>6.869427</td>\n",
       "      <td>5.312102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679322</td>\n",
       "      <td>13.992593</td>\n",
       "      <td>22.770370</td>\n",
       "      <td>12.192593</td>\n",
       "      <td>13.066667</td>\n",
       "      <td>5.148148</td>\n",
       "      <td>4.540741</td>\n",
       "      <td>21.177778</td>\n",
       "      <td>135</td>\n",
       "      <td>-9.474074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team      Wfgp     Wfg3p      Wftp        Wor        Wdr       Wast  \\\n",
       "0  1104  0.466998  0.360334  0.698481  11.956522  25.920949  13.375494   \n",
       "1  1272  0.468580  0.361655  0.672943  13.020000  25.857143  15.934286   \n",
       "2  1266  0.477928  0.380749  0.721663  11.972028  24.541958  16.433566   \n",
       "3  1296  0.472999  0.401041  0.686996  11.468531  25.174825  13.804196   \n",
       "4  1400  0.464493  0.366006  0.690015  13.732484  26.812102  13.671975   \n",
       "\n",
       "         Wto      Wstl      Wblk    ...          Lftp        Lor        Ldr  \\\n",
       "0  12.992095  7.509881  4.865613    ...      0.692350  11.284916  21.715084   \n",
       "1  13.168571  8.771429  5.931429    ...      0.666579  13.188679  22.726415   \n",
       "2  12.860140  8.027972  3.604895    ...      0.681919  11.807947  21.463576   \n",
       "3  14.671329  7.286713  3.902098    ...      0.665492  12.391635  21.665399   \n",
       "4  12.299363  6.869427  5.312102    ...      0.679322  13.992593  22.770370   \n",
       "\n",
       "        Last        Lto      Lstl      Lblk        Lpf  NLoss       Lspr  \n",
       "0  10.458101  13.318436  5.960894  3.782123  19.363128    179  -9.150838  \n",
       "1  11.952830  14.537736  6.830189  5.018868  22.047170    106  -9.245283  \n",
       "2  12.523179  13.728477  5.986755  2.609272  20.278146    151  -9.741722  \n",
       "3  11.019011  15.760456  5.817490  2.874525  20.714829    263 -11.802281  \n",
       "4  12.192593  13.066667  5.148148  4.540741  21.177778    135  -9.474074  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make new table \n",
    "wins = pd.DataFrame()\n",
    "wins_col = ['Season','Wteam', 'Wfgm', 'Wfga', 'Wfgm3', 'Wfga3', 'Wftm',\n",
    "       'Wfta', 'Wor', 'Wdr', 'Wast', 'Wto', 'Wstl', 'Wblk', 'Wpf','Wscore','Lscore']\n",
    "for i in wins_col:\n",
    "    wins[i] = sea_det[i]\n",
    "loss = pd.DataFrame()\n",
    "loss_col = ['Lteam', 'Lfgm','Lfga', 'Lfgm3', 'Lfga3', 'Lftm', 'Lfta', \n",
    "            'Lor', 'Ldr', 'Last', 'Lto','Lstl', 'Lblk', 'Lpf','Wscore','Lscore']\n",
    "for i in loss_col:\n",
    "    loss[i] = sea_det[i]\n",
    "\n",
    "f_df = pd.DataFrame()\n",
    "#print(type(wins['Wteam'].unique()))\n",
    "for k in wins['Wteam'].unique():\n",
    "    ar = []\n",
    "    wins_df = wins[wins['Wteam'] == k]\n",
    "    #season = wins['Season']\n",
    "    Wfgp = np.mean((wins_df['Wfgm']/wins_df['Wfga']))\n",
    "    Wfg3p = np.mean((wins_df['Wfgm3']/wins_df['Wfga3']))\n",
    "    Wftp = np.mean((wins_df['Wftm']/wins_df['Wfta']))\n",
    "    #ar.append(season)\n",
    "    ar.append(k)\n",
    "    ar.append(Wfgp)\n",
    "    ar.append(Wfg3p)\n",
    "    ar.append(Wftp)\n",
    "    \n",
    "    other = ['Wor','Wdr','Wast','Wto','Wstl','Wblk','Wpf']\n",
    "    for i in other:\n",
    "        metric = np.mean(wins_df[i])\n",
    "        ar.append(metric)\n",
    "    NWins = wins_df.shape[0]\n",
    "    ar.append(NWins)\n",
    "    \n",
    "    Wspr = np.mean((wins_df['Wscore'] - wins_df['Lscore']))\n",
    "    ar.append(Wspr)\n",
    "    \n",
    "    #losses\n",
    "    loss_df = loss[loss['Lteam'] == k]\n",
    "    Lfgp = np.mean((loss_df['Lfgm']/loss_df['Lfga']))\n",
    "    Lfg3p = np.mean((loss_df['Lfgm3']/loss_df['Lfga3']))\n",
    "    Lftp = np.mean((loss_df['Lftm']/loss_df['Lfta']))\n",
    "    \n",
    "    ar.append(Lfgp)\n",
    "    ar.append(Lfg3p)\n",
    "    ar.append(Lftp)\n",
    "    other = ['Lor','Ldr','Last','Lto','Lstl','Lblk','Lpf']\n",
    "    for i in other:\n",
    "        metric = np.mean(loss_df[i])\n",
    "        ar.append(metric)\n",
    "    NLoss = loss_df.shape[0]\n",
    "    ar.append(NLoss)\n",
    "    \n",
    "    Lspr = np.mean((loss_df['Lscore'] - loss_df['Wscore']))\n",
    "    ar.append(Lspr)\n",
    "    \n",
    "#     Wpct = NWins/(NWins+NLoss)\n",
    "#     ar.append(Wpct)\n",
    "    \n",
    "#     Lpct = NLoss/(NWins+NLoss)\n",
    "#     ar.append(Lpct)\n",
    "    \n",
    "    f_df = f_df.append([ar], ignore_index= True)\n",
    "f_df.columns = ['Team','Wfgp','Wfg3p','Wftp','Wor','Wdr','Wast',\n",
    "                               'Wto','Wstl','Wblk','Wpf','NWins','Wspr','Lfgp',\n",
    "                               'Lfg3p','Lftp','Lor','Ldr','Last',\n",
    "                               'Lto','Lstl','Lblk','Lpf','NLoss','Lspr']\n",
    "f_df.head()\n",
    "\n",
    "# for item in range(16, len(x)):\n",
    "#     col = x[item][1]\n",
    "#     f_df.drop(col,axis=1,inplace=True)\n",
    "\n",
    "# f_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2798657b64c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;31m# for item in range(10, len(x)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m#     col = x[item][1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#     f_df.drop(col,axis=1,inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "len(x)\n",
    "# for item in range(10, len(x)):\n",
    "#     col = x[item][1]\n",
    "#     f_df.drop(col,axis=1,inplace=True)\n",
    "\n",
    "# f_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Season</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Lteam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1715</td>\n",
       "      <td>2012</td>\n",
       "      <td>1140</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1716</td>\n",
       "      <td>2012</td>\n",
       "      <td>1443</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1717</td>\n",
       "      <td>2012</td>\n",
       "      <td>1378</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1718</td>\n",
       "      <td>2012</td>\n",
       "      <td>1436</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1719</td>\n",
       "      <td>2012</td>\n",
       "      <td>1124</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Season  Wteam  Lteam\n",
       "0   1715    2012   1140   1233\n",
       "1   1716    2012   1443   1290\n",
       "2   1717    2012   1378   1143\n",
       "3   1718    2012   1436   1249\n",
       "4   1719    2012   1124   1355"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tour = pd.read_csv(direct + csv[4])\n",
    "df_tour.drop(labels=['Daynum', 'Wscore', 'Lscore', 'Wloc', 'Numot'], \n",
    "             inplace=True, axis=1)\n",
    "\n",
    "df_tour = df_tour[(df_tour['Season'] == 2012)|(df_tour['Season'] == 2013)|(df_tour['Season'] == 2014)|\n",
    "                  (df_tour['Season'] == 2015)|(df_tour['Season'] == 2016)]\n",
    "df_tour = df_tour.reset_index()\n",
    "df_tour.head()\n",
    "#df_tour = df_tour.rename(columns={'Wteam':'Team'})\n",
    "#df_tour.head()\n",
    "#df_dummy = pd.merge(left=df_tour, right=f_df, how='left', on=['Team'])\n",
    "#df_dummy = df_tour.rename(columns={'Lteam':'Team1'})\n",
    "#df_dummy1 = pd.merge(left=df_dummy, right=f1_df, how='left', on=['Team1'])\n",
    "#df_dummy1.head()\n",
    "# df_concat = pd.merge(left=df_dummy, right=df_lossseeds, on=['Season', 'Lteam'])\n",
    "# df_concat['seed_diff'] = df_concat.win_seed - df_concat.loss_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_diff_table(tour):\n",
    "    df_diff = pd.DataFrame()\n",
    "    for i in range(0,len(tour)):\n",
    "        wteam = tour['Wteam'][i]   \n",
    "        lteam = tour['Lteam'][i] \n",
    "        wteam_stat = (f_df.loc[f_df['Team'] == wteam])\n",
    "        lteam_stat = (f_df.loc[f_df['Team'] == lteam])\n",
    "        diff = pd.DataFrame(wteam_stat.values - lteam_stat.values, columns = wteam_stat.columns)\n",
    "        df_diff = df_diff.append([diff], ignore_index= True)\n",
    "    return df_diff\n",
    "df_diff = create_diff_table(df_tour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Wfgp</th>\n",
       "      <th>Wfg3p</th>\n",
       "      <th>Wftp</th>\n",
       "      <th>Wor</th>\n",
       "      <th>Wdr</th>\n",
       "      <th>Wast</th>\n",
       "      <th>Wto</th>\n",
       "      <th>Wstl</th>\n",
       "      <th>Wblk</th>\n",
       "      <th>...</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "      <th>NLoss</th>\n",
       "      <th>Lspr</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-93.0</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>0.029559</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>2.050581</td>\n",
       "      <td>-0.389677</td>\n",
       "      <td>-0.891226</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>-0.293161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200550</td>\n",
       "      <td>0.254011</td>\n",
       "      <td>-0.899471</td>\n",
       "      <td>-1.817989</td>\n",
       "      <td>-0.637376</td>\n",
       "      <td>-0.759958</td>\n",
       "      <td>0.306751</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-0.463196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.031898</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>0.014994</td>\n",
       "      <td>-1.259990</td>\n",
       "      <td>-0.824993</td>\n",
       "      <td>-0.130704</td>\n",
       "      <td>-0.667019</td>\n",
       "      <td>-1.640019</td>\n",
       "      <td>0.288588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806583</td>\n",
       "      <td>0.810170</td>\n",
       "      <td>1.272204</td>\n",
       "      <td>0.051911</td>\n",
       "      <td>-1.495470</td>\n",
       "      <td>0.673997</td>\n",
       "      <td>-0.147853</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>6.556324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235.0</td>\n",
       "      <td>-0.010479</td>\n",
       "      <td>-0.017501</td>\n",
       "      <td>-0.036924</td>\n",
       "      <td>0.996435</td>\n",
       "      <td>-0.358444</td>\n",
       "      <td>-0.517861</td>\n",
       "      <td>1.157680</td>\n",
       "      <td>1.368168</td>\n",
       "      <td>1.140873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755270</td>\n",
       "      <td>0.425855</td>\n",
       "      <td>-1.492503</td>\n",
       "      <td>1.645291</td>\n",
       "      <td>0.401126</td>\n",
       "      <td>1.129949</td>\n",
       "      <td>-0.567495</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-0.856339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187.0</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>-0.002470</td>\n",
       "      <td>-1.284313</td>\n",
       "      <td>-0.007419</td>\n",
       "      <td>-1.281810</td>\n",
       "      <td>-1.300562</td>\n",
       "      <td>-0.693453</td>\n",
       "      <td>-0.749801</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.121406</td>\n",
       "      <td>-0.277912</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>-1.583397</td>\n",
       "      <td>-0.318067</td>\n",
       "      <td>0.130637</td>\n",
       "      <td>-0.439620</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>3.128403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-231.0</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>-0.038465</td>\n",
       "      <td>2.009377</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>1.910315</td>\n",
       "      <td>2.157682</td>\n",
       "      <td>1.739469</td>\n",
       "      <td>2.456198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589817</td>\n",
       "      <td>-1.575309</td>\n",
       "      <td>-0.370146</td>\n",
       "      <td>-0.546864</td>\n",
       "      <td>1.153108</td>\n",
       "      <td>1.042028</td>\n",
       "      <td>0.621462</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.598492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-264.0</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.342049</td>\n",
       "      <td>1.524747</td>\n",
       "      <td>-1.797141</td>\n",
       "      <td>0.381209</td>\n",
       "      <td>-0.960810</td>\n",
       "      <td>-0.034991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390744</td>\n",
       "      <td>-0.780148</td>\n",
       "      <td>-0.999588</td>\n",
       "      <td>1.032571</td>\n",
       "      <td>-0.138425</td>\n",
       "      <td>-0.525046</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-3.647702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-241.0</td>\n",
       "      <td>0.035709</td>\n",
       "      <td>0.027823</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>-1.699855</td>\n",
       "      <td>3.905383</td>\n",
       "      <td>-1.092596</td>\n",
       "      <td>0.732721</td>\n",
       "      <td>-1.089392</td>\n",
       "      <td>-0.315385</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.723679</td>\n",
       "      <td>3.717880</td>\n",
       "      <td>0.141959</td>\n",
       "      <td>1.668872</td>\n",
       "      <td>-0.926489</td>\n",
       "      <td>0.262191</td>\n",
       "      <td>0.720003</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>2.820551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-77.0</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>-0.881743</td>\n",
       "      <td>0.031254</td>\n",
       "      <td>0.964076</td>\n",
       "      <td>-0.984297</td>\n",
       "      <td>0.366261</td>\n",
       "      <td>-0.086895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504993</td>\n",
       "      <td>-1.462502</td>\n",
       "      <td>-0.622103</td>\n",
       "      <td>-1.076691</td>\n",
       "      <td>-0.084134</td>\n",
       "      <td>-0.482099</td>\n",
       "      <td>0.742321</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.692858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>-0.004588</td>\n",
       "      <td>-0.008497</td>\n",
       "      <td>-2.389664</td>\n",
       "      <td>-0.828449</td>\n",
       "      <td>0.964787</td>\n",
       "      <td>-0.600418</td>\n",
       "      <td>0.248999</td>\n",
       "      <td>-3.490616</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.157374</td>\n",
       "      <td>-1.137442</td>\n",
       "      <td>0.486528</td>\n",
       "      <td>-0.489545</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>-2.915810</td>\n",
       "      <td>0.103527</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-2.328644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-136.0</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>-0.042816</td>\n",
       "      <td>1.452191</td>\n",
       "      <td>-0.172058</td>\n",
       "      <td>3.643972</td>\n",
       "      <td>0.983011</td>\n",
       "      <td>0.109854</td>\n",
       "      <td>0.911255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.785050</td>\n",
       "      <td>-0.174160</td>\n",
       "      <td>2.217972</td>\n",
       "      <td>-0.042875</td>\n",
       "      <td>0.248519</td>\n",
       "      <td>0.790095</td>\n",
       "      <td>1.480481</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>3.061881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-197.0</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>-0.015892</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.060906</td>\n",
       "      <td>1.755061</td>\n",
       "      <td>1.473649</td>\n",
       "      <td>-0.922791</td>\n",
       "      <td>0.179050</td>\n",
       "      <td>2.578575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.684687</td>\n",
       "      <td>0.669076</td>\n",
       "      <td>0.198931</td>\n",
       "      <td>-0.712993</td>\n",
       "      <td>0.294175</td>\n",
       "      <td>1.682743</td>\n",
       "      <td>0.101318</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>1.223532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.011058</td>\n",
       "      <td>-0.027863</td>\n",
       "      <td>-0.055465</td>\n",
       "      <td>1.855563</td>\n",
       "      <td>-1.024178</td>\n",
       "      <td>0.572493</td>\n",
       "      <td>0.172535</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>2.194880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458505</td>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-1.027383</td>\n",
       "      <td>-0.689544</td>\n",
       "      <td>1.894670</td>\n",
       "      <td>1.828770</td>\n",
       "      <td>-0.150711</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>3.798935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>126.0</td>\n",
       "      <td>-0.009955</td>\n",
       "      <td>-0.014410</td>\n",
       "      <td>-0.005889</td>\n",
       "      <td>1.026867</td>\n",
       "      <td>-2.980623</td>\n",
       "      <td>-0.356756</td>\n",
       "      <td>0.563366</td>\n",
       "      <td>0.457004</td>\n",
       "      <td>-0.049944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128053</td>\n",
       "      <td>-1.208424</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.128477</td>\n",
       "      <td>-0.037245</td>\n",
       "      <td>-0.302728</td>\n",
       "      <td>-0.705854</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.045722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>132.0</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>-0.019415</td>\n",
       "      <td>0.801707</td>\n",
       "      <td>-1.324902</td>\n",
       "      <td>0.727177</td>\n",
       "      <td>-0.176791</td>\n",
       "      <td>1.360558</td>\n",
       "      <td>0.139645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422660</td>\n",
       "      <td>-1.992158</td>\n",
       "      <td>0.823764</td>\n",
       "      <td>-0.111094</td>\n",
       "      <td>1.259074</td>\n",
       "      <td>-0.121300</td>\n",
       "      <td>0.043901</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>2.192749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>-0.807982</td>\n",
       "      <td>0.945614</td>\n",
       "      <td>1.917807</td>\n",
       "      <td>-1.175789</td>\n",
       "      <td>-0.409561</td>\n",
       "      <td>0.577632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.956407</td>\n",
       "      <td>0.518014</td>\n",
       "      <td>-0.036728</td>\n",
       "      <td>-1.922201</td>\n",
       "      <td>-0.123033</td>\n",
       "      <td>0.599945</td>\n",
       "      <td>0.297375</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>3.268759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>-0.034967</td>\n",
       "      <td>-1.150586</td>\n",
       "      <td>0.689396</td>\n",
       "      <td>1.845411</td>\n",
       "      <td>-2.013177</td>\n",
       "      <td>0.173023</td>\n",
       "      <td>0.269886</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.423675</td>\n",
       "      <td>-0.175765</td>\n",
       "      <td>-0.068576</td>\n",
       "      <td>-1.655575</td>\n",
       "      <td>-0.174865</td>\n",
       "      <td>0.189397</td>\n",
       "      <td>-1.628376</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>2.635545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-28.0</td>\n",
       "      <td>-0.006166</td>\n",
       "      <td>-0.013649</td>\n",
       "      <td>-0.052496</td>\n",
       "      <td>1.927019</td>\n",
       "      <td>-0.134317</td>\n",
       "      <td>0.553830</td>\n",
       "      <td>-0.824534</td>\n",
       "      <td>0.956263</td>\n",
       "      <td>1.741201</td>\n",
       "      <td>...</td>\n",
       "      <td>1.769311</td>\n",
       "      <td>-0.246487</td>\n",
       "      <td>0.693564</td>\n",
       "      <td>-2.661927</td>\n",
       "      <td>0.380935</td>\n",
       "      <td>1.240916</td>\n",
       "      <td>-0.385341</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>4.581275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-22.0</td>\n",
       "      <td>-0.011761</td>\n",
       "      <td>0.011588</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>0.759362</td>\n",
       "      <td>-2.281761</td>\n",
       "      <td>-0.984842</td>\n",
       "      <td>-0.250422</td>\n",
       "      <td>2.851143</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386003</td>\n",
       "      <td>-0.690290</td>\n",
       "      <td>-1.144010</td>\n",
       "      <td>-0.244010</td>\n",
       "      <td>1.442119</td>\n",
       "      <td>0.733417</td>\n",
       "      <td>0.609206</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-0.130517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>218.0</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.027261</td>\n",
       "      <td>-0.037414</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>1.726019</td>\n",
       "      <td>1.245527</td>\n",
       "      <td>-0.826043</td>\n",
       "      <td>-1.195306</td>\n",
       "      <td>0.102213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501273</td>\n",
       "      <td>0.065742</td>\n",
       "      <td>0.872987</td>\n",
       "      <td>-2.101761</td>\n",
       "      <td>-0.992913</td>\n",
       "      <td>0.030377</td>\n",
       "      <td>0.075272</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.779895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>173.0</td>\n",
       "      <td>-0.025184</td>\n",
       "      <td>-0.016452</td>\n",
       "      <td>-0.005216</td>\n",
       "      <td>1.371587</td>\n",
       "      <td>-0.108926</td>\n",
       "      <td>-0.932660</td>\n",
       "      <td>-2.753400</td>\n",
       "      <td>-0.548944</td>\n",
       "      <td>-0.085304</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285118</td>\n",
       "      <td>-1.155489</td>\n",
       "      <td>-1.099099</td>\n",
       "      <td>-3.123123</td>\n",
       "      <td>-0.286787</td>\n",
       "      <td>-0.306640</td>\n",
       "      <td>-3.505339</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>2.208709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team      Wfgp     Wfg3p      Wftp       Wor       Wdr      Wast  \\\n",
       "0   -93.0  0.000390 -0.002991  0.029559  0.009161  2.050581 -0.389677   \n",
       "1   153.0  0.031898  0.017543  0.014994 -1.259990 -0.824993 -0.130704   \n",
       "2   235.0 -0.010479 -0.017501 -0.036924  0.996435 -0.358444 -0.517861   \n",
       "3   187.0  0.009109 -0.004872 -0.002470 -1.284313 -0.007419 -1.281810   \n",
       "4  -231.0  0.014899 -0.002090 -0.038465  2.009377  0.098160  1.910315   \n",
       "5  -264.0  0.008165  0.014938  0.004940  0.342049  1.524747 -1.797141   \n",
       "6  -241.0  0.035709  0.027823  0.027683 -1.699855  3.905383 -1.092596   \n",
       "7   -77.0 -0.000406  0.029444  0.038025 -0.881743  0.031254  0.964076   \n",
       "8    72.0  0.002696 -0.004588 -0.008497 -2.389664 -0.828449  0.964787   \n",
       "9  -136.0  0.003210  0.022630 -0.042816  1.452191 -0.172058  3.643972   \n",
       "10 -197.0  0.014026 -0.015892  0.003568  0.060906  1.755061  1.473649   \n",
       "11   85.0 -0.011058 -0.027863 -0.055465  1.855563 -1.024178  0.572493   \n",
       "12  126.0 -0.009955 -0.014410 -0.005889  1.026867 -2.980623 -0.356756   \n",
       "13  132.0 -0.004025  0.008397 -0.019415  0.801707 -1.324902  0.727177   \n",
       "14   54.0  0.006179  0.019787  0.014944 -0.807982  0.945614  1.917807   \n",
       "15   67.0  0.027650 -0.002606 -0.034967 -1.150586  0.689396  1.845411   \n",
       "16  -28.0 -0.006166 -0.013649 -0.052496  1.927019 -0.134317  0.553830   \n",
       "17  -22.0 -0.011761  0.011588 -0.027273  0.759362 -2.281761 -0.984842   \n",
       "18  218.0  0.001776  0.027261 -0.037414  0.277108  1.726019  1.245527   \n",
       "19  173.0 -0.025184 -0.016452 -0.005216  1.371587 -0.108926 -0.932660   \n",
       "\n",
       "         Wto      Wstl      Wblk   ...         Lor       Ldr      Last  \\\n",
       "0  -0.891226  0.038968 -0.293161   ...    0.200550  0.254011 -0.899471   \n",
       "1  -0.667019 -1.640019  0.288588   ...    0.806583  0.810170  1.272204   \n",
       "2   1.157680  1.368168  1.140873   ...    0.755270  0.425855 -1.492503   \n",
       "3  -1.300562 -0.693453 -0.749801   ...   -1.121406 -0.277912  0.044271   \n",
       "4   2.157682  1.739469  2.456198   ...    0.589817 -1.575309 -0.370146   \n",
       "5   0.381209 -0.960810 -0.034991   ...    0.390744 -0.780148 -0.999588   \n",
       "6   0.732721 -1.089392 -0.315385   ...   -1.723679  3.717880  0.141959   \n",
       "7  -0.984297  0.366261 -0.086895   ...   -0.504993 -1.462502 -0.622103   \n",
       "8  -0.600418  0.248999 -3.490616   ...   -2.157374 -1.137442  0.486528   \n",
       "9   0.983011  0.109854  0.911255   ...    1.785050 -0.174160  2.217972   \n",
       "10 -0.922791  0.179050  2.578575   ...   -0.684687  0.669076  0.198931   \n",
       "11  0.172535  3.014286  2.194880   ...    0.458505 -0.666293 -1.027383   \n",
       "12  0.563366  0.457004 -0.049944   ...   -0.128053 -1.208424  0.523179   \n",
       "13 -0.176791  1.360558  0.139645   ...    0.422660 -1.992158  0.823764   \n",
       "14 -1.175789 -0.409561  0.577632   ...   -0.956407  0.518014 -0.036728   \n",
       "15 -2.013177  0.173023  0.269886   ...   -1.423675 -0.175765 -0.068576   \n",
       "16 -0.824534  0.956263  1.741201   ...    1.769311 -0.246487  0.693564   \n",
       "17 -0.250422  2.851143  0.656455   ...    0.386003 -0.690290 -1.144010   \n",
       "18 -0.826043 -1.195306  0.102213   ...   -0.501273  0.065742  0.872987   \n",
       "19 -2.753400 -0.548944 -0.085304   ...    1.285118 -1.155489 -1.099099   \n",
       "\n",
       "         Lto      Lstl      Lblk       Lpf  NLoss      Lspr  result  \n",
       "0  -1.817989 -0.637376 -0.759958  0.306751  -64.0 -0.463196       1  \n",
       "1   0.051911 -1.495470  0.673997 -0.147853  -97.0  6.556324       1  \n",
       "2   1.645291  0.401126  1.129949 -0.567495   93.0 -0.856339       1  \n",
       "3  -1.583397 -0.318067  0.130637 -0.439620  -87.0  3.128403       1  \n",
       "4  -0.546864  1.153108  1.042028  0.621462   20.0  0.598492       1  \n",
       "5   1.032571 -0.138425 -0.525046  0.496599   51.0 -3.647702       1  \n",
       "6   1.668872 -0.926489  0.262191  0.720003  -82.0  2.820551       1  \n",
       "7  -1.076691 -0.084134 -0.482099  0.742321    9.0 -0.692858       1  \n",
       "8  -0.489545  0.034169 -2.915810  0.103527   51.0 -2.328644       1  \n",
       "9  -0.042875  0.248519  0.790095  1.480481  -29.0  3.061881       1  \n",
       "10 -0.712993  0.294175  1.682743  0.101318  -62.0  1.223532       1  \n",
       "11 -0.689544  1.894670  1.828770 -0.150711  -22.0  3.798935       1  \n",
       "12  0.128477 -0.037245 -0.302728 -0.705854   26.0 -0.045722       1  \n",
       "13 -0.111094  1.259074 -0.121300  0.043901  -78.0  2.192749       1  \n",
       "14 -1.922201 -0.123033  0.599945  0.297375  -67.0  3.268759       1  \n",
       "15 -1.655575 -0.174865  0.189397 -1.628376 -115.0  2.635545       1  \n",
       "16 -2.661927  0.380935  1.240916 -0.385341  -97.0  4.581275       1  \n",
       "17 -0.244010  1.442119  0.733417  0.609206   -8.0 -0.130517       1  \n",
       "18 -2.101761 -0.992913  0.030377  0.075272   -3.0  1.779895       1  \n",
       "19 -3.123123 -0.286787 -0.306640 -3.505339  -51.0  2.208709       1  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "df_wins = pd.DataFrame()\n",
    "df_wins = df_diff\n",
    "df_wins['result'] = 1\n",
    "\n",
    "df_losses = pd.DataFrame()\n",
    "df_losses = -df_diff\n",
    "df_losses['result'] = 0\n",
    "\n",
    "# Randomly select left and right and 0 or 1 so we can train\n",
    "# for multiple classes.\n",
    "# df_pred = df_diff \n",
    "# df_pred['result'] = 1\n",
    "# for i in range(len(df_pred)):\n",
    "#     if random.random() > 0.5:\n",
    "#         df_pred['result'][i] = 1\n",
    "#     else:\n",
    "#         df_pred.loc[i:i] = -df_diff.loc[i:i]\n",
    "#         df_pred['result'][i] = 0 \n",
    "\n",
    "df_pred = pd.concat((df_wins, df_losses))\n",
    "df_pred.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pred.drop('Team',inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = df_pred.drop('result',axis=1)\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "\n",
    "y_train = df_pred['result']\n",
    "\n",
    "# kf = KFold(n_splits = 5, shuffle = True, random_state=8)\n",
    "\n",
    "# model_LR= LogisticRegression()\n",
    "# params = {'C': np.logspace(start=-5, stop=3, num=9)}\n",
    "# model_LR = GridSearchCV(model_LR, params, scoring='neg_log_loss', refit=True)\n",
    "# model_LR.fit(X_train,y_train)\n",
    "\n",
    "# pred_probs = model_LR.predict_proba(X_train)\n",
    "# predictions = model_LR.predict(X_train)\n",
    "\n",
    "# accuracies = cross_val_score(model_LR, X_train, y_train, scoring='accuracy', cv=kf)\n",
    "# average_accuracies = np.mean(accuracies)\n",
    "# print(average_accuracies)\n",
    "\n",
    "# actual = y_train\n",
    "# count= ((predictions-actual)**2).sum()\n",
    "# mse = count/len(actual)\n",
    "# print(mse)\n",
    "\n",
    "# loss = log_loss(y_train, predictions)\n",
    "# print(loss)\n",
    "\n",
    "# print(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541791044776\n",
      "0.721709355703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=1, algorithm = 'ball_tree', leaf_size = 10, p=2, weights = 'distance')\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state=8)\n",
    "\n",
    "#print(knn.get_params().keys())\n",
    "\n",
    "#params = {'C': np.logspace(start=-5, stop=3, num=9)}\n",
    "# model_LR = GridSearchCV(knn, params, scoring='neg_log_loss', refit=True)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#pred_probs = knn.predict_proba(X_train)\n",
    "predictions = knn.predict(X_train)\n",
    "\n",
    "accuracies = cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=kf)\n",
    "average_accuracies = np.mean(accuracies)\n",
    "print(average_accuracies)\n",
    "\n",
    "# actual = y_train\n",
    "# count= ((predictions-actual)**2).sum()\n",
    "# mse = count/len(actual)\n",
    "# print(mse)\n",
    "\n",
    "loss = log_loss(y_train, predictions)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e7b47ade601c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mauc_roc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_probs' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(y_train,predictions)\n",
    "\n",
    "auc_roc=metrics.roc_auc_score(y_train,predictions)\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, pred_probs[:,1])\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],linestyle='--')\n",
    "plt.axis('tight')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.17760000000000001, 'NWins'), (0.087099999999999997, 'Wspr'), (0.047300000000000002, 'Lspr'), (0.046100000000000002, 'Lftp'), (0.0436, 'Wpf'), (0.040099999999999997, 'Lto'), (0.0395, 'Wast'), (0.037600000000000001, 'Ldr'), (0.036499999999999998, 'Wfgp'), (0.036299999999999999, 'Wto'), (0.036200000000000003, 'Lpf'), (0.0361, 'Wftp'), (0.032800000000000003, 'Lfgp'), (0.031600000000000003, 'Lor'), (0.029999999999999999, 'Wor'), (0.029999999999999999, 'Wdr'), (0.029700000000000001, 'Wblk'), (0.0293, 'Lfg3p'), (0.0292, 'Lstl'), (0.029000000000000001, 'Wfg3p'), (0.027699999999999999, 'Last'), (0.024500000000000001, 'NLoss'), (0.021700000000000001, 'Lblk'), (0.020899999999999998, 'Wstl')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "names = df_pred.columns\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))\n",
    "x = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1, 'NLoss'), (2, 'Wast'), (3, 'Last'), (4, 'Wpf'), (5, 'Lspr'), (6, 'Wto'), (7, 'Lftp'), (8, 'Lor'), (9, 'Wor'), (10, 'Wspr'), (11, 'Lfgp'), (12, 'Wftp'), (13, 'Lto'), (14, 'Ldr'), (15, 'NWins'), (16, 'Lpf'), (17, 'Lfg3p'), (18, 'Wfgp'), (19, 'Wstl'), (20, 'Wblk'), (21, 'Wdr'), (22, 'Lstl'), (23, 'Wfg3p'), (24, 'Lblk')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#use linear regression as the model\n",
    "lr = LinearRegression()\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "rfe.fit(X_train,y_train)\n",
    " \n",
    "print (\"Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.0, 'Wto'), (0.0, 'Wstl'), (0.0, 'Wspr'), (0.0, 'Wpf'), (0.0, 'Wor'), (0.0, 'Wftp'), (0.0, 'Wfgp'), (0.0, 'Wfg3p'), (0.0, 'Wdr'), (0.0, 'Wblk'), (0.0, 'Wast'), (0.0, 'NWins'), (0.0, 'NLoss'), (0.0, 'Lto'), (0.0, 'Lstl'), (0.0, 'Lspr'), (0.0, 'Lpf'), (0.0, 'Lor'), (0.0, 'Lftp'), (0.0, 'Lfgp'), (0.0, 'Lfg3p'), (0.0, 'Ldr'), (0.0, 'Lblk'), (0.0, 'Last')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.025)\n",
    "rlasso.fit(X_train, y_train)\n",
    " \n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), \n",
    "                 names), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(355, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>-0.007541</td>\n",
       "      <td>-0.056143</td>\n",
       "      <td>0.271352</td>\n",
       "      <td>-1.211525</td>\n",
       "      <td>2.262954</td>\n",
       "      <td>-0.502680</td>\n",
       "      <td>0.695384</td>\n",
       "      <td>1.274598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030773</td>\n",
       "      <td>0.487059</td>\n",
       "      <td>-1.284314</td>\n",
       "      <td>1.049608</td>\n",
       "      <td>-0.690980</td>\n",
       "      <td>0.844902</td>\n",
       "      <td>0.918431</td>\n",
       "      <td>2.169608</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>1.758627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-0.017124</td>\n",
       "      <td>-0.011784</td>\n",
       "      <td>-0.041633</td>\n",
       "      <td>-0.553130</td>\n",
       "      <td>-1.631391</td>\n",
       "      <td>-0.886344</td>\n",
       "      <td>-0.221075</td>\n",
       "      <td>0.078662</td>\n",
       "      <td>0.054531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047421</td>\n",
       "      <td>0.217049</td>\n",
       "      <td>-1.896175</td>\n",
       "      <td>-0.635301</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.692459</td>\n",
       "      <td>-0.116284</td>\n",
       "      <td>2.197814</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.240328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-22.0</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>-0.012996</td>\n",
       "      <td>-0.026795</td>\n",
       "      <td>0.673724</td>\n",
       "      <td>-0.837773</td>\n",
       "      <td>-1.820050</td>\n",
       "      <td>-1.187353</td>\n",
       "      <td>-0.959308</td>\n",
       "      <td>1.085870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>0.869851</td>\n",
       "      <td>-1.121891</td>\n",
       "      <td>-2.269751</td>\n",
       "      <td>-2.518607</td>\n",
       "      <td>-0.495821</td>\n",
       "      <td>0.842488</td>\n",
       "      <td>-0.358706</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.104179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-26.0</td>\n",
       "      <td>-0.009533</td>\n",
       "      <td>-0.008884</td>\n",
       "      <td>-0.029204</td>\n",
       "      <td>0.816688</td>\n",
       "      <td>-0.809342</td>\n",
       "      <td>0.566220</td>\n",
       "      <td>-0.059058</td>\n",
       "      <td>0.378119</td>\n",
       "      <td>1.012718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010657</td>\n",
       "      <td>0.889724</td>\n",
       "      <td>-1.777164</td>\n",
       "      <td>-0.329576</td>\n",
       "      <td>-0.434291</td>\n",
       "      <td>0.290276</td>\n",
       "      <td>0.713849</td>\n",
       "      <td>0.671639</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>0.326740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-34.0</td>\n",
       "      <td>-0.003681</td>\n",
       "      <td>-0.015142</td>\n",
       "      <td>-0.044440</td>\n",
       "      <td>1.965210</td>\n",
       "      <td>-1.474016</td>\n",
       "      <td>1.279517</td>\n",
       "      <td>0.131550</td>\n",
       "      <td>1.064742</td>\n",
       "      <td>0.940367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012216</td>\n",
       "      <td>1.937701</td>\n",
       "      <td>-1.810345</td>\n",
       "      <td>-0.018851</td>\n",
       "      <td>-0.785977</td>\n",
       "      <td>0.937701</td>\n",
       "      <td>0.742299</td>\n",
       "      <td>0.739080</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0.825057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  -4.0  0.001940 -0.007541 -0.056143  0.271352 -1.211525  2.262954 -0.502680   \n",
       "1  -9.0 -0.017124 -0.011784 -0.041633 -0.553130 -1.631391 -0.886344 -0.221075   \n",
       "2 -22.0 -0.027074 -0.012996 -0.026795  0.673724 -0.837773 -1.820050 -1.187353   \n",
       "3 -26.0 -0.009533 -0.008884 -0.029204  0.816688 -0.809342  0.566220 -0.059058   \n",
       "4 -34.0 -0.003681 -0.015142 -0.044440  1.965210 -1.474016  1.279517  0.131550   \n",
       "\n",
       "         8         9     ...           15        16        17        18  \\\n",
       "0  0.695384  1.274598    ...    -0.030773  0.487059 -1.284314  1.049608   \n",
       "1  0.078662  0.054531    ...    -0.047421  0.217049 -1.896175 -0.635301   \n",
       "2 -0.959308  1.085870    ...    -0.004947  0.869851 -1.121891 -2.269751   \n",
       "3  0.378119  1.012718    ...    -0.010657  0.889724 -1.777164 -0.329576   \n",
       "4  1.064742  0.940367    ...    -0.012216  1.937701 -1.810345 -0.018851   \n",
       "\n",
       "         19        20        21        22    23        24  \n",
       "0 -0.690980  0.844902  0.918431  2.169608 -54.0  1.758627  \n",
       "1  0.093333  0.692459 -0.116284  2.197814  28.0 -1.240328  \n",
       "2 -2.518607 -0.495821  0.842488 -0.358706  16.0  0.104179  \n",
       "3 -0.434291  0.290276  0.713849  0.671639 -31.0  0.326740  \n",
       "4 -0.785977  0.937701  0.742299  0.739080 -24.0  0.825057  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "df_sample_sub = pd.read_csv(direct+csv[8])\n",
    "\n",
    "n_test_games = len(df_sample_sub)\n",
    "print(f_df.shape)\n",
    "\n",
    "def get_year_t1_t2(id):\n",
    "    return (int(x) for x in id.split('_'))\n",
    "\n",
    "# df_diff = create_diff_table(df_tour)\n",
    "# df_diff.head()\n",
    "\n",
    "# X_test = np.zeros(shape=(n_test_games, 25))\n",
    "X_test = pd.DataFrame()\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, t1, t2 = get_year_t1_t2(row.id)\n",
    "    t1_stat = (f_df.loc[f_df['Team'] == t1])\n",
    "    t2_stat = (f_df.loc[f_df['Team'] == t2])\n",
    "    diff = pd.DataFrame(t1_stat.values - t2_stat.values)\n",
    "    X_test = X_test.append([diff], ignore_index= True)\n",
    "X_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9112, 25)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.drop(0,inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013_1103_1107</td>\n",
       "      <td>0.648610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013_1103_1112</td>\n",
       "      <td>0.212488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013_1103_1125</td>\n",
       "      <td>0.591842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013_1103_1129</td>\n",
       "      <td>0.729963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013_1103_1137</td>\n",
       "      <td>0.667460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      pred\n",
       "0  2013_1103_1107  0.648610\n",
       "1  2013_1103_1112  0.212488\n",
       "2  2013_1103_1125  0.591842\n",
       "3  2013_1103_1129  0.729963\n",
       "4  2013_1103_1137  0.667460"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=scaler.fit_transform(X_test)\n",
    "preds = model_LR.predict_proba(X_test)[:,1]\n",
    "\n",
    "clipped_preds = np.clip(preds, 0.05, 0.95)\n",
    "df_sample_sub.pred = clipped_preds\n",
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_sub.to_csv('danny_mm_17.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.\n",
      "  1.  1.  1.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.\n",
      "  1.  1.  1.  1.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.\n",
      "  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  1.  1.  0.  0.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.\n",
      "  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  0.\n",
      "  1.  1.  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.\n",
      "  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.]\n",
      "0.005970149253731343\n",
      "0.610962566845\n",
      "0.206206423835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create the knn model.\n",
    "# i1 = []\n",
    "# mse1 = []\n",
    "#for i in range(1,300):\n",
    "knn = KNeighborsRegressor(n_neighbors=1, algorithm = 'ball_tree', leaf_size = 10)\n",
    "# Fit the model on the training data.\n",
    "knn.fit(X_train, y_train)\n",
    "# Make predictions on the test set using the fit model.\n",
    "predictions = knn.predict(X_train)\n",
    "print(predictions)\n",
    "# for y in range(len(predictions)):\n",
    "#     if predictions[y] >= 0.5:\n",
    "#         predictions[y] = 1\n",
    "#     else:\n",
    "#         predictions[y] = 0\n",
    "\n",
    "actual = y_train\n",
    "count= ((predictions-actual)**2).sum()\n",
    "mse = count/len(actual)\n",
    "print(mse)\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=10)\n",
    "average_accuracies = np.mean(accuracies)\n",
    "print(average_accuracies)\n",
    "\n",
    "\n",
    "loss = log_loss(y_train, predictions)\n",
    "print(loss)\n",
    "\n",
    "# i1.append(i)\n",
    "# mse1.append(mse)\n",
    "# print(predictions)\n",
    "#print(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x162cddbedd8>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAFkCAYAAAAdXVDGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x162cddeceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(i1,mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
