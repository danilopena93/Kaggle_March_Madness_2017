{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "File b'data-v2/RegularSeasonDetailedResults.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-24ab49edd3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0minitialize_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mseason_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/RegularSeasonDetailedResults.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0mtourney_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/TourneyDetailedResults.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mseason_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtourney_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'data-v2/RegularSeasonDetailedResults.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import cross_validation, linear_model\n",
    "import csv\n",
    "import random\n",
    "\n",
    "base_elo = 1600\n",
    "team_elos = {}  # Reset each year.\n",
    "team_stats = {}\n",
    "X = []\n",
    "y = []\n",
    "submission_data = []\n",
    "folder = 'data-v2'\n",
    "prediction_year = 2016\n",
    "\n",
    "\n",
    "def calc_elo(win_team, lose_team, season):\n",
    "    winner_rank = get_elo(season, win_team)\n",
    "    loser_rank = get_elo(season, lose_team)\n",
    "\n",
    "    \"\"\"\n",
    "    This is originally from from:\n",
    "    http://zurb.com/forrst/posts/An_Elo_Rating_function_in_Python_written_for_foo-hQl\n",
    "    \"\"\"\n",
    "    rank_diff = winner_rank - loser_rank\n",
    "    exp = (rank_diff * -1) / 400\n",
    "    odds = 1 / (1 + math.pow(10, exp))\n",
    "    if winner_rank < 2100:\n",
    "        k = 32\n",
    "    elif winner_rank >= 2100 and winner_rank < 2400:\n",
    "        k = 24\n",
    "    else:\n",
    "        k = 16\n",
    "    new_winner_rank = round(winner_rank + (k * (1 - odds)))\n",
    "    new_rank_diff = new_winner_rank - winner_rank\n",
    "    new_loser_rank = loser_rank - new_rank_diff\n",
    "\n",
    "    return new_winner_rank, new_loser_rank\n",
    "\n",
    "\n",
    "def initialize_data():\n",
    "    for i in range(1985, 2017):\n",
    "        team_elos[i] = {}\n",
    "        team_stats[i] = {}\n",
    "\n",
    "\n",
    "def get_elo(season, team):\n",
    "    try:\n",
    "        return team_elos[season][team]\n",
    "    except:\n",
    "        try:\n",
    "            # Get the previous season's ending value.\n",
    "            team_elos[season][team] = team_elos[season-1][team]\n",
    "            return team_elos[season][team]\n",
    "        except:\n",
    "            # Get the starter elo.\n",
    "            team_elos[season][team] = base_elo\n",
    "            return team_elos[season][team]\n",
    "\n",
    "\n",
    "def predict_winner(team_1, team_2, model, season, stat_fields):\n",
    "    features = []\n",
    "\n",
    "    # Team 1\n",
    "    features.append(get_elo(season, team_1))\n",
    "    for stat in stat_fields:\n",
    "        features.append(get_stat(season, team_1, stat))\n",
    "\n",
    "    # Team 2\n",
    "    features.append(get_elo(season, team_2))\n",
    "    for stat in stat_fields:\n",
    "        features.append(get_stat(season, team_2, stat))\n",
    "\n",
    "    return model.predict_proba([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_stats(season, team, fields):\n",
    "    \"\"\"\n",
    "    This accepts some stats for a team and udpates the averages.\n",
    "    First, we check if the team is in the dict yet. If it's not, we add it.\n",
    "    Then, we try to check if the key has more than 5 values in it.\n",
    "        If it does, we remove the first one\n",
    "        Either way, we append the new one.\n",
    "    If we can't check, then it doesn't exist, so we just add this.\n",
    "    Later, we'll get the average of these items.\n",
    "    \"\"\"\n",
    "    if team not in team_stats[season]:\n",
    "        team_stats[season][team] = {}\n",
    "\n",
    "    for key, value in fields.items():\n",
    "        # Make sure we have the field.\n",
    "        if key not in team_stats[season][team]:\n",
    "            team_stats[season][team][key] = []\n",
    "\n",
    "        if len(team_stats[season][team][key]) >= 9:\n",
    "            team_stats[season][team][key].pop()\n",
    "        team_stats[season][team][key].append(value)\n",
    "\n",
    "\n",
    "def get_stat(season, team, field):\n",
    "    try:\n",
    "        l = team_stats[season][team][field]\n",
    "        return sum(l) / float(len(l))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_team_dict():\n",
    "    team_ids = pd.read_csv(folder + '/Teams.csv')\n",
    "    team_id_map = {}\n",
    "    for index, row in team_ids.iterrows():\n",
    "        team_id_map[row['Team_Id']] = row['Team_Name']\n",
    "    return team_id_map\n",
    "\n",
    "\n",
    "def build_season_data(all_data):\n",
    "    # Calculate the elo for every game for every team, each season.\n",
    "    # Store the elo per season so we can retrieve their end elo\n",
    "    # later in order to predict the tournaments without having to\n",
    "    # inject the prediction into this loop.\n",
    "    print(\"Building season data.\")\n",
    "    for index, row in all_data.iterrows():\n",
    "        # Used to skip matchups where we don't have usable stats yet.\n",
    "        skip = 0\n",
    "\n",
    "        # Get starter or previous elos.\n",
    "        team_1_elo = get_elo(row['Season'], row['Wteam'])\n",
    "        team_2_elo = get_elo(row['Season'], row['Lteam'])\n",
    "\n",
    "        # Add 100 to the home team (# taken from Nate Silver analysis.)\n",
    "        if row['Wloc'] == 'H':\n",
    "            team_1_elo += 100\n",
    "        elif row['Wloc'] == 'A':\n",
    "            team_2_elo += 100\n",
    "\n",
    "        # We'll create some arrays to use later.\n",
    "        team_1_features = [team_1_elo]\n",
    "        team_2_features = [team_2_elo]\n",
    "\n",
    "        # Build arrays out of the stats we're tracking..\n",
    "        for field in stat_fields:\n",
    "            team_1_stat = get_stat(row['Season'], row['Wteam'], field)\n",
    "            team_2_stat = get_stat(row['Season'], row['Lteam'], field)\n",
    "            if team_1_stat is not 0 and team_2_stat is not 0:\n",
    "                team_1_features.append(team_1_stat)\n",
    "                team_2_features.append(team_2_stat)\n",
    "            else:\n",
    "                skip = 1\n",
    "\n",
    "        if skip == 0:  # Make sure we have stats.\n",
    "            # Randomly select left and right and 0 or 1 so we can train\n",
    "            # for multiple classes.\n",
    "            if random.random() > 0.5:\n",
    "                X.append(team_1_features + team_2_features)\n",
    "                y.append(0)\n",
    "            else:\n",
    "                X.append(team_2_features + team_1_features)\n",
    "                y.append(1)\n",
    "\n",
    "        # AFTER we add the current stuff to the prediction, update for\n",
    "        # next time. Order here is key so we don't fit on data from the\n",
    "        # same game we're trying to predict.\n",
    "        if row['Wfta'] != 0 and row['Lfta'] != 0:\n",
    "            stat_1_fields = {\n",
    "                'score': row['Wscore'],\n",
    "                'fgp': row['Wfgm'] / row['Wfga'] * 100,\n",
    "                'fga': row['Wfga'],\n",
    "                'fga3': row['Wfga3'],\n",
    "                '3pp': row['Wfgm3'] / row['Wfga3'] * 100,\n",
    "                'ftp': row['Wftm'] / row['Wfta'] * 100,\n",
    "                'or': row['Wor'],\n",
    "                'dr': row['Wdr'],\n",
    "                'ast': row['Wast'],\n",
    "                'to': row['Wto'],\n",
    "                'stl': row['Wstl'],\n",
    "                'blk': row['Wblk'],\n",
    "                'pf': row['Wpf']\n",
    "            }\n",
    "            stat_2_fields = {\n",
    "                'score': row['Lscore'],\n",
    "                'fgp': row['Lfgm'] / row['Lfga'] * 100,\n",
    "                'fga': row['Lfga'],\n",
    "                'fga3': row['Lfga3'],\n",
    "                '3pp': row['Lfgm3'] / row['Lfga3'] * 100,\n",
    "                'ftp': row['Lftm'] / row['Lfta'] * 100,\n",
    "                'or': row['Lor'],\n",
    "                'dr': row['Ldr'],\n",
    "                'ast': row['Last'],\n",
    "                'to': row['Lto'],\n",
    "                'stl': row['Lstl'],\n",
    "                'blk': row['Lblk'],\n",
    "                'pf': row['Lpf']\n",
    "            }\n",
    "            update_stats(row['Season'], row['Wteam'], stat_1_fields)\n",
    "            update_stats(row['Season'], row['Lteam'], stat_2_fields)\n",
    "\n",
    "        # Now that we've added them, calc the new elo.\n",
    "        new_winner_rank, new_loser_rank = calc_elo(\n",
    "            row['Wteam'], row['Lteam'], row['Season'])\n",
    "        team_elos[row['Season']][row['Wteam']] = new_winner_rank\n",
    "        team_elos[row['Season']][row['Lteam']] = new_loser_rank\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    stat_fields = ['score', 'fga', 'fgp', 'fga3', '3pp', 'ftp', 'or', 'dr',\n",
    "                   'ast', 'to', 'stl', 'blk', 'pf']\n",
    "\n",
    "    initialize_data()\n",
    "    season_data = pd.read_csv(folder + '/RegularSeasonDetailedResults.csv')\n",
    "    tourney_data = pd.read_csv(folder + '/TourneyDetailedResults.csv')\n",
    "    frames = [season_data, tourney_data]\n",
    "    all_data = pd.concat(frames)\n",
    "\n",
    "    # Build the working data.\n",
    "    X, y = build_season_data(all_data)\n",
    "\n",
    "    # Fit the model.\n",
    "    print(\"Fitting on %d samples.\" % len(X))\n",
    "\n",
    "    model = linear_model.LogisticRegression()\n",
    "\n",
    "    # Check accuracy.\n",
    "    print(\"Doing cross-validation.\")\n",
    "    print(cross_validation.cross_val_score(\n",
    "        model, X, y, cv=10, scoring='accuracy', n_jobs=-1\n",
    "    ).mean())\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Now predict tournament matchups.\n",
    "    print(\"Getting teams.\")\n",
    "    seeds = pd.read_csv(folder + '/TourneySeeds.csv')\n",
    "    # for i in range(2016, 2017):\n",
    "    tourney_teams = []\n",
    "    for index, row in seeds.iterrows():\n",
    "        if row['Season'] == prediction_year:\n",
    "            tourney_teams.append(row['Team'])\n",
    "\n",
    "    # Build our prediction of every matchup.\n",
    "    print(\"Predicting matchups.\")\n",
    "    tourney_teams.sort()\n",
    "    for team_1 in tourney_teams:\n",
    "        for team_2 in tourney_teams:\n",
    "            if team_1 < team_2:\n",
    "                prediction = predict_winner(\n",
    "                    team_1, team_2, model, prediction_year, stat_fields)\n",
    "                label = str(prediction_year) + '_' + str(team_1) + '_' + \\\n",
    "                    str(team_2)\n",
    "                submission_data.append([label, prediction[0][0]])\n",
    "\n",
    "    # Write the results.\n",
    "    print(\"Writing %d results.\" % len(submission_data))\n",
    "    with open(folder + '/submission.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'pred'])\n",
    "        writer.writerows(submission_data)\n",
    "\n",
    "    # Now so that we can use this to fill out a bracket, create a readable\n",
    "    # version.\n",
    "    print(\"Outputting readable results.\")\n",
    "    team_id_map = build_team_dict()\n",
    "    readable = []\n",
    "    less_readable = []  # A version that's easy to look up.\n",
    "    for pred in submission_data:\n",
    "        parts = pred[0].split('_')\n",
    "        less_readable.append(\n",
    "            [team_id_map[int(parts[1])], team_id_map[int(parts[2])], pred[1]])\n",
    "        # Order them properly.\n",
    "        if pred[1] > 0.5:\n",
    "            winning = int(parts[1])\n",
    "            losing = int(parts[2])\n",
    "            proba = pred[1]\n",
    "        else:\n",
    "            winning = int(parts[2])\n",
    "            losing = int(parts[1])\n",
    "            proba = 1 - pred[1]\n",
    "        readable.append(\n",
    "            [\n",
    "                '%s beats %s: %f' %\n",
    "                (team_id_map[winning], team_id_map[losing], proba)\n",
    "            ]\n",
    "        )\n",
    "    with open(folder + '/readable-predictions.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(readable)\n",
    "    with open(folder + '/less-readable-predictions.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(less_readable)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
